{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7295ee70",
   "metadata": {},
   "source": [
    "# Graph Neural Network Training Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d423f8",
   "metadata": {},
   "source": [
    "Multi-Dataset Graph Classification with Noise-Robust Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c8955b",
   "metadata": {},
   "source": [
    "## 1. Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6228bc1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T15:26:10.500035Z",
     "iopub.status.busy": "2025-05-26T15:26:10.499694Z",
     "iopub.status.idle": "2025-05-26T15:26:19.442973Z",
     "shell.execute_reply": "2025-05-26T15:26:19.441067Z",
     "shell.execute_reply.started": "2025-05-26T15:26:10.500006Z"
    },
    "id": "xSkgt1zf-raF",
    "outputId": "59f4a52f-5eb4-41e5-9fba-07432989fe78",
    "papermill": {
     "duration": 5.620104,
     "end_time": "2025-05-21T16:23:24.361690",
     "exception": false,
     "start_time": "2025-05-21T16:23:18.741586",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch_geometric\n",
      "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.18)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (1.26.4)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (7.0.0)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.0.9)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.20.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.4.26)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch_geometric) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch_geometric) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torch_geometric) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torch_geometric) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torch_geometric) (2024.2.0)\n",
      "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch_geometric\n",
      "Successfully installed torch_geometric-2.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c86aceda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T15:26:19.445388Z",
     "iopub.status.busy": "2025-05-26T15:26:19.445010Z",
     "iopub.status.idle": "2025-05-26T15:26:19.451995Z",
     "shell.execute_reply": "2025-05-26T15:26:19.450805Z",
     "shell.execute_reply.started": "2025-05-26T15:26:19.445353Z"
    },
    "id": "5oR2D2Us-xSQ",
    "outputId": "7086cadf-a7fe-4d75-f271-6339bee8164d",
    "papermill": {
     "duration": 4.049235,
     "end_time": "2025-05-21T16:23:28.415556",
     "exception": false,
     "start_time": "2025-05-21T16:23:24.366321",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !git clone --branch baselineCe https://github.com/Graph-Classification-Noisy-Label/hackaton.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c129091c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T15:26:19.454591Z",
     "iopub.status.busy": "2025-05-26T15:26:19.454201Z",
     "iopub.status.idle": "2025-05-26T15:26:19.478396Z",
     "shell.execute_reply": "2025-05-26T15:26:19.476730Z",
     "shell.execute_reply.started": "2025-05-26T15:26:19.454562Z"
    },
    "id": "tEhfPly6-7UK",
    "outputId": "3078ee06-6312-4fca-f5f9-888fa628c80a",
    "papermill": {
     "duration": 0.013251,
     "end_time": "2025-05-21T16:23:28.434119",
     "exception": false,
     "start_time": "2025-05-21T16:23:28.420868",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# %cd hackaton/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d48103c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T15:26:19.480030Z",
     "iopub.status.busy": "2025-05-26T15:26:19.479642Z",
     "iopub.status.idle": "2025-05-26T15:26:19.514193Z",
     "shell.execute_reply": "2025-05-26T15:26:19.512341Z",
     "shell.execute_reply.started": "2025-05-26T15:26:19.479990Z"
    },
    "id": "PxBvwB0_6xI8",
    "outputId": "5933387c-2cfb-474f-d842-f36a3e2d2a73",
    "papermill": {
     "duration": 83.957666,
     "end_time": "2025-05-21T16:24:52.396720",
     "exception": false,
     "start_time": "2025-05-21T16:23:28.439054",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !gdown --folder https://drive.google.com/drive/folders/1Z-1JkPJ6q4C6jX4brvq1VRbJH5RPUCAk -O datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80dab1bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T15:26:19.516347Z",
     "iopub.status.busy": "2025-05-26T15:26:19.515926Z",
     "iopub.status.idle": "2025-05-26T15:26:19.543790Z",
     "shell.execute_reply": "2025-05-26T15:26:19.542695Z",
     "shell.execute_reply.started": "2025-05-26T15:26:19.516312Z"
    },
    "id": "1rockhiQ7Nny",
    "outputId": "2cd2e6f4-5f8f-4a62-f0ec-53e6fc78c9b7",
    "papermill": {
     "duration": 0.138969,
     "end_time": "2025-05-21T16:24:52.549260",
     "exception": false,
     "start_time": "2025-05-21T16:24:52.410291",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !ls -lh datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "817b1078",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T15:26:19.546066Z",
     "iopub.status.busy": "2025-05-26T15:26:19.545508Z",
     "iopub.status.idle": "2025-05-26T15:26:36.250419Z",
     "shell.execute_reply": "2025-05-26T15:26:36.249268Z",
     "shell.execute_reply.started": "2025-05-26T15:26:19.546003Z"
    },
    "id": "lAQuCuIoBbq5",
    "papermill": {
     "duration": 9.949638,
     "end_time": "2025-05-21T16:25:02.510764",
     "exception": false,
     "start_time": "2025-05-21T16:24:52.561126",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08bedc6f-2af6-428f-a7db-c00a24038b98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T15:26:36.252271Z",
     "iopub.status.busy": "2025-05-26T15:26:36.251566Z",
     "iopub.status.idle": "2025-05-26T15:26:37.527456Z",
     "shell.execute_reply": "2025-05-26T15:26:37.525418Z",
     "shell.execute_reply.started": "2025-05-26T15:26:36.252230Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added '/kaggle/input/d/leonardosandri/myhackatonhelperscripts/' to sys.path.\n",
      "Contents of '/kaggle/input/d/leonardosandri/myhackatonhelperscripts/': ['zipthefolder.py', 'loadData.py', 'utils.py', 'models.py', 'conv.py', 'preprocessor.py', '__init__.py']\n",
      "Successfully imported modules.\n"
     ]
    }
   ],
   "source": [
    "helper_scripts_path = '/kaggle/input/d/leonardosandri/myhackatonhelperscripts/'\n",
    "\n",
    "if os.path.exists(helper_scripts_path):\n",
    "    # Add this path to the beginning of Python's search list\n",
    "    sys.path.insert(0, helper_scripts_path)\n",
    "    print(f\"Successfully added '{helper_scripts_path}' to sys.path.\")\n",
    "    print(f\"Contents of '{helper_scripts_path}': {os.listdir(helper_scripts_path)}\") # Verify\n",
    "else:\n",
    "    print(f\"WARNING: Helper scripts path not found: {helper_scripts_path}\")\n",
    "    print(\"Please ensure 'myhackathonhelperscripts' dataset is correctly added to the notebook.\")\n",
    "\n",
    "# Start import of utils modules\n",
    "try:\n",
    "    from preprocessor import MultiDatasetLoader\n",
    "    from utils import set_seed\n",
    "    # from conv import GINConv as OriginalRepoGINConv\n",
    "    from models import GNN\n",
    "    print(\"Successfully imported modules.\")\n",
    "except ImportError as e:\n",
    "    print(f\"ERROR importing module: {e}\")\n",
    "    print(\"Please check that the .py files exist directly under the helper_scripts_path and have no syntax errors.\")\n",
    "    # print(\"Current sys.path:\", sys.path)\n",
    "\n",
    "# Set the random seed\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f544afa5",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a9c70d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T15:28:13.252292Z",
     "iopub.status.busy": "2025-05-26T15:28:13.251400Z",
     "iopub.status.idle": "2025-05-26T15:28:13.259014Z",
     "shell.execute_reply": "2025-05-26T15:28:13.257576Z",
     "shell.execute_reply.started": "2025-05-26T15:28:13.252217Z"
    },
    "id": "Dyf0I2-t9IcW",
    "papermill": {
     "duration": 0.019268,
     "end_time": "2025-05-21T16:25:02.544583",
     "exception": false,
     "start_time": "2025-05-21T16:25:02.525315",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def add_zeros(data):\n",
    "    if data.x is None or data.x.shape[0] != data.num_nodes:\n",
    "        data.x = torch.zeros(data.num_nodes, 1, dtype=torch.long)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0944127",
   "metadata": {},
   "source": [
    "## 3. Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3622cfa1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T15:28:16.994021Z",
     "iopub.status.busy": "2025-05-26T15:28:16.993571Z",
     "iopub.status.idle": "2025-05-26T15:28:17.008804Z",
     "shell.execute_reply": "2025-05-26T15:28:17.007089Z",
     "shell.execute_reply.started": "2025-05-26T15:28:16.993990Z"
    },
    "id": "3jKvoQYI9Zbc",
    "papermill": {
     "duration": 0.019599,
     "end_time": "2025-05-21T16:25:02.577661",
     "exception": false,
     "start_time": "2025-05-21T16:25:02.558062",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train(data_loader, model, optimizer, criterion, device, save_checkpoints, checkpoint_path, current_epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in tqdm(data_loader, desc=\"Iterating training graphs\", unit=\"batch\"):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        try:\n",
    "            output = model(data)\n",
    "        except IndexError as e:\n",
    "            print(f\"Error in batch with {data.num_nodes} nodes, edge_max={data.edge_index.max()}\")\n",
    "            print(f\"Batch info: x.shape={data.x.shape}, edge_index.shape={data.edge_index.shape}\")\n",
    "            raise e\n",
    "        loss = criterion(output, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        pred = output.argmax(dim=1)\n",
    "        correct += (pred == data.y).sum().item()\n",
    "        total += data.y.size(0)\n",
    "\n",
    "    # Save checkpoints if required\n",
    "    if save_checkpoints:\n",
    "        checkpoint_file = f\"{checkpoint_path}_epoch_{current_epoch + 1}.pth\"\n",
    "        torch.save(model.state_dict(), checkpoint_file)\n",
    "        print(f\"Checkpoint saved at {checkpoint_file}\")\n",
    "\n",
    "    return total_loss / len(data_loader),  correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6139b912",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T15:28:24.614916Z",
     "iopub.status.busy": "2025-05-26T15:28:24.614494Z",
     "iopub.status.idle": "2025-05-26T15:28:24.623522Z",
     "shell.execute_reply": "2025-05-26T15:28:24.621850Z",
     "shell.execute_reply.started": "2025-05-26T15:28:24.614888Z"
    },
    "id": "8peFiIS19ZpK",
    "papermill": {
     "duration": 0.017908,
     "end_time": "2025-05-21T16:25:02.607848",
     "exception": false,
     "start_time": "2025-05-21T16:25:02.589940",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate(data_loader, model, device, calculate_accuracy=False):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predictions = []\n",
    "    total_loss = 0\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(data_loader, desc=\"Iterating eval graphs\", unit=\"batch\"):\n",
    "            data = data.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            \n",
    "            if calculate_accuracy:\n",
    "                correct += (pred == data.y).sum().item()\n",
    "                total += data.y.size(0)\n",
    "                total_loss += criterion(output, data.y).item()\n",
    "            else:\n",
    "                predictions.extend(pred.cpu().numpy())\n",
    "    if calculate_accuracy:\n",
    "        accuracy = correct / total\n",
    "        return  total_loss / len(data_loader),accuracy\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bba939",
   "metadata": {},
   "source": [
    "## 4. Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbdbd871",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T15:28:27.814894Z",
     "iopub.status.busy": "2025-05-26T15:28:27.813444Z",
     "iopub.status.idle": "2025-05-26T15:28:27.821991Z",
     "shell.execute_reply": "2025-05-26T15:28:27.820695Z",
     "shell.execute_reply.started": "2025-05-26T15:28:27.814851Z"
    },
    "id": "WanuZKxy9Zs-",
    "papermill": {
     "duration": 0.016728,
     "end_time": "2025-05-21T16:25:02.635694",
     "exception": false,
     "start_time": "2025-05-21T16:25:02.618966",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def save_predictions(predictions, test_path):\n",
    "    script_dir = os.getcwd() \n",
    "    submission_folder = os.path.join(script_dir, \"submission\")\n",
    "    test_dir_name = os.path.basename(os.path.dirname(test_path))\n",
    "    \n",
    "    os.makedirs(submission_folder, exist_ok=True)\n",
    "    \n",
    "    output_csv_path = os.path.join(submission_folder, f\"testset_{test_dir_name}.csv\")\n",
    "    \n",
    "    test_graph_ids = list(range(len(predictions)))\n",
    "    output_df = pd.DataFrame({\n",
    "        \"id\": test_graph_ids,\n",
    "        \"pred\": predictions\n",
    "    })\n",
    "    \n",
    "    output_df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"Predictions saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc3d24da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T15:28:28.593101Z",
     "iopub.status.busy": "2025-05-26T15:28:28.591823Z",
     "iopub.status.idle": "2025-05-26T15:28:28.603036Z",
     "shell.execute_reply": "2025-05-26T15:28:28.601493Z",
     "shell.execute_reply.started": "2025-05-26T15:28:28.593025Z"
    },
    "id": "uyHIJS5U9ZzB",
    "papermill": {
     "duration": 0.017765,
     "end_time": "2025-05-21T16:25:02.664538",
     "exception": false,
     "start_time": "2025-05-21T16:25:02.646773",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_training_progress(train_losses, train_accuracies, output_dir):\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_losses, label=\"Training Loss\", color='blue')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss per Epoch')\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, train_accuracies, label=\"Training Accuracy\", color='green')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training Accuracy per Epoch')\n",
    "\n",
    "    # Save plots in the current directory\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, \"training_progress.png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0864fa6c",
   "metadata": {},
   "source": [
    "## 5. Configuration and Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22574fa5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T15:28:32.137777Z",
     "iopub.status.busy": "2025-05-26T15:28:32.137340Z",
     "iopub.status.idle": "2025-05-26T15:28:32.144984Z",
     "shell.execute_reply": "2025-05-26T15:28:32.143675Z",
     "shell.execute_reply.started": "2025-05-26T15:28:32.137747Z"
    },
    "papermill": {
     "duration": 0.016577,
     "end_time": "2025-05-21T16:25:02.692205",
     "exception": false,
     "start_time": "2025-05-21T16:25:02.675628",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_user_input(prompt, default=None, required=False, type_cast=str):\n",
    "\n",
    "    while True:\n",
    "        user_input = input(f\"{prompt} [{default}]: \")\n",
    "        \n",
    "        if user_input == \"\" and required:\n",
    "            print(\"This field is required. Please enter a value.\")\n",
    "            continue\n",
    "        \n",
    "        if user_input == \"\" and default is not None:\n",
    "            return default\n",
    "        \n",
    "        if user_input == \"\" and not required:\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            return type_cast(user_input)\n",
    "        except ValueError:\n",
    "            print(f\"Invalid input. Please enter a valid {type_cast.__name__}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "139e88b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T15:42:54.835761Z",
     "iopub.status.busy": "2025-05-26T15:42:54.835326Z",
     "iopub.status.idle": "2025-05-26T15:42:54.842457Z",
     "shell.execute_reply": "2025-05-26T15:42:54.841151Z",
     "shell.execute_reply.started": "2025-05-26T15:42:54.835732Z"
    },
    "papermill": {
     "duration": 0.017703,
     "end_time": "2025-05-21T16:25:02.721184",
     "exception": false,
     "start_time": "2025-05-21T16:25:02.703481",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_arguments():\n",
    "    \"\"\"Set training configuration directly\"\"\"\n",
    "    args = {\n",
    "        # Dataset selection\n",
    "        'dataset': 'A',  # Choose: A, B, C, D\n",
    "        'train_mode': 1,  # 1=single dataset, 2=all datasets\n",
    "        \n",
    "        # Model config\n",
    "        'gnn': 'gin',  # gin, gin-virtual, gcn, gcn-virtual\n",
    "        'drop_ratio': 0.0,\n",
    "        'num_layer': 5,\n",
    "        'emb_dim': 300,\n",
    "        \n",
    "        # Training config\n",
    "        'batch_size': 32,\n",
    "        'epochs': 10,\n",
    "        'baseline_mode': 1,  # 1=CE, 2=Noisy CE\n",
    "        'noise_prob': 0.2,\n",
    "        \n",
    "        # System config\n",
    "        'device': 0,\n",
    "        'num_checkpoints': 3\n",
    "    }\n",
    "    return argparse.Namespace(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45bffa19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T15:28:34.237011Z",
     "iopub.status.busy": "2025-05-26T15:28:34.236562Z",
     "iopub.status.idle": "2025-05-26T15:28:34.247629Z",
     "shell.execute_reply": "2025-05-26T15:28:34.245779Z",
     "shell.execute_reply.started": "2025-05-26T15:28:34.236983Z"
    },
    "papermill": {
     "duration": 0.118164,
     "end_time": "2025-05-21T16:25:02.850799",
     "exception": true,
     "start_time": "2025-05-21T16:25:02.732635",
     "status": "failed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arguments received:\n",
      "dataset: A\n",
      "train_mode: 1\n",
      "gnn: gin\n",
      "drop_ratio: 0.0\n",
      "num_layer: 5\n",
      "emb_dim: 300\n",
      "batch_size: 1\n",
      "epochs: 10\n",
      "baseline_mode: 1\n",
      "noise_prob: 0.2\n",
      "device: 0\n",
      "num_checkpoints: 3\n"
     ]
    }
   ],
   "source": [
    "def populate_args(args):\n",
    "    print(\"Arguments received:\")\n",
    "    for key, value in vars(args).items():\n",
    "        print(f\"{key}: {value}\")\n",
    "args = get_arguments()\n",
    "populate_args(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40170fe",
   "metadata": {},
   "source": [
    "## 6. Loss Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09b57d62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T15:28:37.569081Z",
     "iopub.status.busy": "2025-05-26T15:28:37.568701Z",
     "iopub.status.idle": "2025-05-26T15:28:37.578631Z",
     "shell.execute_reply": "2025-05-26T15:28:37.577262Z",
     "shell.execute_reply.started": "2025-05-26T15:28:37.569056Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class NoisyCrossEntropyLoss(torch.nn.Module):\n",
    "    def __init__(self, p_noisy):\n",
    "        super().__init__()\n",
    "        self.p = p_noisy\n",
    "        self.ce = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        losses = self.ce(logits, targets)\n",
    "        weights = (1 - self.p) + self.p * (1 - torch.nn.functional.one_hot(targets, num_classes=logits.size(1)).float().sum(dim=1))\n",
    "        return (losses * weights).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e319a162",
   "metadata": {},
   "source": [
    "## 7. Main training pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a210abf8",
   "metadata": {},
   "source": [
    "### 7.1 Config section\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24a82d11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T15:28:38.377713Z",
     "iopub.status.busy": "2025-05-26T15:28:38.377273Z",
     "iopub.status.idle": "2025-05-26T15:28:38.386674Z",
     "shell.execute_reply": "2025-05-26T15:28:38.384972Z",
     "shell.execute_reply.started": "2025-05-26T15:28:38.377685Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Enhanced GNN Training Pipeline\n",
      "============================================================\n",
      "\n",
      "Configuration:\n",
      "  dataset: A\n",
      "  train_mode: 1\n",
      "  gnn: gin\n",
      "  drop_ratio: 0.0\n",
      "  num_layer: 5\n",
      "  emb_dim: 300\n",
      "  batch_size: 1\n",
      "  epochs: 10\n",
      "  baseline_mode: 1\n",
      "  noise_prob: 0.2\n",
      "  device: 0\n",
      "  num_checkpoints: 3\n",
      "\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Enhanced GNN Training Pipeline\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get configuration\n",
    "args = get_arguments()\n",
    "\n",
    "print(\"\\nConfiguration:\")\n",
    "for key, value in vars(args).items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Setup device\n",
    "device = torch.device(f\"cuda:{args.device}\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nUsing device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26506118",
   "metadata": {},
   "source": [
    "### 7.2 Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81432ff3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T15:44:07.617721Z",
     "iopub.status.busy": "2025-05-26T15:44:07.617264Z",
     "iopub.status.idle": "2025-05-26T15:44:18.645662Z",
     "shell.execute_reply": "2025-05-26T15:44:18.644176Z",
     "shell.execute_reply.started": "2025-05-26T15:44:07.617689Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "LOADING DATA\n",
      "========================================\n",
      "Using single dataset: A\n",
      "Train samples: 10152\n",
      "Val samples: 1128\n",
      "Test samples: 2340\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"LOADING DATA\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "base_path = '/kaggle/input/deep-dataset-preprocessed/processed_data_separate'\n",
    "\n",
    "# Prepare training/validation data based on mode\n",
    "if args.train_mode == 1:\n",
    "    # Single dataset mode\n",
    "    dataset_name = args.dataset\n",
    "    train_dataset = torch.load(f'{base_path}/{dataset_name}_train_graphs.pt', weights_only=False)\n",
    "    val_dataset = torch.load(f'{base_path}/{dataset_name}_val_graphs.pt', weights_only=False)\n",
    "    test_dataset = torch.load(f'{base_path}/{dataset_name}_test_graphs.pt', weights_only=False)\n",
    "    print(f\"Using single dataset: {dataset_name}\")\n",
    "else:\n",
    "    # All datasets mode\n",
    "    train_dataset = []\n",
    "    val_dataset = []\n",
    "    test_dataset = torch.load(f'{base_path}/{args.dataset}_test_graphs.pt', weights_only=False)  # Test on specified dataset\n",
    "    \n",
    "    for ds_name in ['A', 'B', 'C', 'D']:\n",
    "        train_dataset.extend(torch.load(f'{base_path}/{ds_name}_train_graphs.pt', weights_only=False))\n",
    "        val_dataset.extend(torch.load(f'{base_path}/{ds_name}_val_graphs.pt', weights_only=False))\n",
    "    \n",
    "    print(\"Using all datasets for training\")\n",
    "\n",
    "print(f\"Train samples: {len(train_dataset)}\")\n",
    "print(f\"Val samples: {len(val_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43dd45fc-c3b6-4dfd-964a-ae99a3f77a23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T15:44:18.650989Z",
     "iopub.status.busy": "2025-05-26T15:44:18.648772Z",
     "iopub.status.idle": "2025-05-26T15:44:18.990835Z",
     "shell.execute_reply": "2025-05-26T15:44:18.989703Z",
     "shell.execute_reply.started": "2025-05-26T15:44:18.650936Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for i, data in enumerate(train_dataset):\n",
    "    if data.edge_index.numel() > 0 and data.edge_index.max() >= data.num_nodes:\n",
    "        print(f\"Problem graph {i}: edge_max={data.edge_index.max()}, nodes={data.num_nodes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63613e69",
   "metadata": {},
   "source": [
    "### 7.3 Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "269b5bb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T15:44:18.996989Z",
     "iopub.status.busy": "2025-05-26T15:44:18.996531Z",
     "iopub.status.idle": "2025-05-26T15:44:19.051049Z",
     "shell.execute_reply": "2025-05-26T15:44:19.049692Z",
     "shell.execute_reply.started": "2025-05-26T15:44:18.996962Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "MODEL SETUP\n",
      "========================================\n",
      "Using standard Cross Entropy Loss\n",
      "Model parameters: 1,827,611\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"MODEL SETUP\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Initialize model\n",
    "if args.gnn == 'gin':\n",
    "    model = GNN(gnn_type='gin', num_class=6, num_layer=args.num_layer, \n",
    "               emb_dim=args.emb_dim, drop_ratio=args.drop_ratio, virtual_node=False)\n",
    "elif args.gnn == 'gin-virtual':\n",
    "    model = GNN(gnn_type='gin', num_class=6, num_layer=args.num_layer,\n",
    "               emb_dim=args.emb_dim, drop_ratio=args.drop_ratio, virtual_node=True)\n",
    "elif args.gnn == 'gcn':\n",
    "    model = GNN(gnn_type='gcn', num_class=6, num_layer=args.num_layer,\n",
    "               emb_dim=args.emb_dim, drop_ratio=args.drop_ratio, virtual_node=False)\n",
    "elif args.gnn == 'gcn-virtual':\n",
    "    model = GNN(gnn_type='gcn', num_class=6, num_layer=args.num_layer,\n",
    "               emb_dim=args.emb_dim, drop_ratio=args.drop_ratio, virtual_node=True)\n",
    "else:\n",
    "    raise ValueError(f'Invalid GNN type: {args.gnn}')\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Setup optimizer and loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "if args.baseline_mode == 2:\n",
    "    criterion = NoisyCrossEntropyLoss(args.noise_prob)\n",
    "    print(f\"Using Noisy Cross Entropy Loss (p={args.noise_prob})\")\n",
    "else:\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    print(\"Using standard Cross Entropy Loss\")\n",
    "\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# Setup logging and checkpoints\n",
    "exp_name = f\"{args.gnn}_dataset{args.dataset}_mode{args.train_mode}\"\n",
    "logs_dir = os.path.join(\"logs\", exp_name)\n",
    "checkpoints_dir = os.path.join(\"checkpoints\", exp_name)\n",
    "os.makedirs(logs_dir, exist_ok=True)\n",
    "os.makedirs(checkpoints_dir, exist_ok=True)\n",
    "\n",
    "# Setup logging\n",
    "log_file = os.path.join(logs_dir, \"training.log\")\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_file),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "best_model_path = os.path.join(checkpoints_dir, \"best_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25032fa3",
   "metadata": {},
   "source": [
    "### 7.4 Training loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad0e3701",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T15:44:19.053289Z",
     "iopub.status.busy": "2025-05-26T15:44:19.052946Z",
     "iopub.status.idle": "2025-05-26T15:44:19.151358Z",
     "shell.execute_reply": "2025-05-26T15:44:19.148886Z",
     "shell.execute_reply.started": "2025-05-26T15:44:19.053264Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "TRAINING\n",
      "========================================\n",
      "\n",
      "Epoch 1/10\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterating training graphs:   0%|          | 0/10152 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in batch with 300 nodes, edge_max=299\n",
      "Batch info: x.shape=torch.Size([300, 1]), edge_index.shape=torch.Size([2, 4940])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Found indices in 'edge_index' that are larger than 0 (got 299). Please ensure that all indices in 'edge_index' point to valid indices in the interval [0, 1) in your node feature matrix and try again.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36m_index_select_safe\u001b[0;34m(self, src, index)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mIndexError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: INDICES element is out of DATA bounds, id=1 axis_dim=1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35/3169538069.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     train_loss, train_acc = train(\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0msave_checkpoints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheckpoint_intervals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_35/2734806706.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data_loader, model, optimizer, criterion, device, save_checkpoints, checkpoint_path, current_epoch)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error in batch with {data.num_nodes} nodes, edge_max={data.edge_index.max()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Batch info: x.shape={data.x.shape}, edge_index.shape={data.edge_index.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_35/2734806706.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data_loader, model, optimizer, criterion, device, save_checkpoints, checkpoint_path, current_epoch)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error in batch with {data.num_nodes} nodes, edge_max={data.edge_index.max()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kaggle/input/d/leonardosandri/myhackatonhelperscripts/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batched_data)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mh_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgnn_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mh_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kaggle/input/d/leonardosandri/myhackatonhelperscripts/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batched_data)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_norms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kaggle/input/d/leonardosandri/myhackatonhelperscripts/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0medge_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medge_embedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/conv_GINConv_propagate_3fem5sxx.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, x, edge_attr, size)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         kwargs = self.collect(\n\u001b[0m\u001b[1;32m    158\u001b[0m             \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/conv_GINConv_propagate_3fem5sxx.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self, edge_index, x, edge_attr, size)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mx_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index_j\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mx_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36m_index_select\u001b[0;34m(self, src, index)\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_select_safe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_index_select_safe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36m_index_select_safe\u001b[0;34m(self, src, index)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m                 raise IndexError(\n\u001b[0m\u001b[1;32m    283\u001b[0m                     \u001b[0;34mf\"Found indices in 'edge_index' that are larger \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m                     \u001b[0;34mf\"than {src.size(self.node_dim) - 1} (got \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Found indices in 'edge_index' that are larger than 0 (got 299). Please ensure that all indices in 'edge_index' point to valid indices in the interval [0, 1) in your node feature matrix and try again."
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"TRAINING\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "best_val_accuracy = 0.0\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "# Calculate checkpoint intervals\n",
    "if args.num_checkpoints > 1:\n",
    "    checkpoint_intervals = [int((i + 1) * args.epochs / args.num_checkpoints) \n",
    "                          for i in range(args.num_checkpoints)]\n",
    "else:\n",
    "    checkpoint_intervals = [args.epochs]\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{args.epochs}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Training\n",
    "    train_loss, train_acc = train(\n",
    "        train_loader, model, optimizer, criterion, device,\n",
    "        save_checkpoints=(epoch + 1 in checkpoint_intervals),\n",
    "        checkpoint_path=os.path.join(checkpoints_dir, \"checkpoint\"),\n",
    "        current_epoch=epoch\n",
    "    )\n",
    "    \n",
    "    # Validation\n",
    "    val_loss, val_acc = evaluate(val_loader, model, device, calculate_accuracy=True)\n",
    "    \n",
    "    # Log results\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    logging.info(f\"Epoch {epoch + 1}: Train Loss={train_loss:.4f}, Train Acc={train_acc:.4f}, \"\n",
    "                f\"Val Loss={val_loss:.4f}, Val Acc={val_acc:.4f}\")\n",
    "    \n",
    "    # Store metrics\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_accuracy:\n",
    "        best_val_accuracy = val_acc\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"★ New best model saved! Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "print(f\"\\nBest validation accuracy: {best_val_accuracy:.4f}\")\n",
    "\n",
    "# Plot training progress\n",
    "plot_training_progress(train_losses, train_accuracies, val_losses, val_accuracies, logs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13ece3f6-dd29-4f6d-beb0-c4295bf32074",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T15:46:23.308303Z",
     "iopub.status.busy": "2025-05-26T15:46:23.307907Z",
     "iopub.status.idle": "2025-05-26T15:46:23.322729Z",
     "shell.execute_reply": "2025-05-26T15:46:23.321512Z",
     "shell.execute_reply.started": "2025-05-26T15:46:23.308277Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader batch: x=torch.Size([300, 1]), edge_max=299\n"
     ]
    }
   ],
   "source": [
    "# Test DataLoader batching directly\n",
    "for batch in train_loader:\n",
    "    print(f\"DataLoader batch: x={batch.x.shape}, edge_max={batch.edge_index.max()}\")\n",
    "    if batch.x.shape[0] <= batch.edge_index.max():\n",
    "        print(\"FOUND CORRUPTED BATCH!\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25604a74",
   "metadata": {},
   "source": [
    "### 7.5 Testing and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de27e926",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-26T15:44:19.152214Z",
     "iopub.status.idle": "2025-05-26T15:44:19.152667Z",
     "shell.execute_reply": "2025-05-26T15:44:19.152475Z",
     "shell.execute_reply.started": "2025-05-26T15:44:19.152458Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"TESTING\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Load best model and make predictions\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "print(f\"Loaded best model from: {best_model_path}\")\n",
    "\n",
    "predictions = evaluate(test_loader, model, device, calculate_accuracy=False)\n",
    "\n",
    "# Save predictions\n",
    "save_predictions(predictions, args.dataset)\n",
    "\n",
    "# Cleanup\n",
    "del train_dataset, val_dataset, test_dataset\n",
    "del train_loader, val_loader, test_loader\n",
    "gc.collect()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Best validation accuracy: {best_val_accuracy:.4f}\")\n",
    "print(f\"Predictions saved for dataset {args.dataset}\")\n",
    "print(f\"Logs and plots saved in: {logs_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be039b0e-005f-4884-b31e-b5d364a2529d",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc0e197-332f-4f35-9901-011b14a4dfd0",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12470721,
     "datasetId": 7519186,
     "sourceId": 11958675,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 12471309,
     "datasetId": 7519473,
     "sourceId": 11959204,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "DeepTest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 108.457758,
   "end_time": "2025-05-21T16:25:04.482169",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-21T16:23:16.024411",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
