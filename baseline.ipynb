{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11958675,"sourceType":"datasetVersion","datasetId":7519186},{"sourceId":11959204,"sourceType":"datasetVersion","datasetId":7519473}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":108.457758,"end_time":"2025-05-21T16:25:04.482169","environment_variables":{},"exception":true,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-05-21T16:23:16.024411","version":"2.6.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"7295ee70","cell_type":"markdown","source":"# Graph Neural Network Training Pipeline","metadata":{}},{"id":"52d423f8","cell_type":"markdown","source":"Multi-Dataset Graph Classification with Noise-Robust Training","metadata":{}},{"id":"10c8955b","cell_type":"markdown","source":"## 1. Setup and Dependencies","metadata":{}},{"id":"6228bc1c","cell_type":"code","source":"!pip install torch_geometric","metadata":{"id":"xSkgt1zf-raF","outputId":"59f4a52f-5eb4-41e5-9fba-07432989fe78","papermill":{"duration":5.620104,"end_time":"2025-05-21T16:23:24.361690","exception":false,"start_time":"2025-05-21T16:23:18.741586","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T17:15:35.623447Z","iopub.execute_input":"2025-05-26T17:15:35.623670Z","iopub.status.idle":"2025-05-26T17:15:41.984520Z","shell.execute_reply.started":"2025-05-26T17:15:35.623652Z","shell.execute_reply":"2025-05-26T17:15:41.983518Z"}},"outputs":[{"name":"stdout","text":"Collecting torch_geometric\n  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.18)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (7.0.0)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.0.9)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.20.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.4.26)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch_geometric) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch_geometric) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torch_geometric) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torch_geometric) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torch_geometric) (2024.2.0)\nDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torch_geometric\nSuccessfully installed torch_geometric-2.6.1\n","output_type":"stream"}],"execution_count":1},{"id":"c86aceda","cell_type":"code","source":"# !git clone --branch baselineCe https://github.com/Graph-Classification-Noisy-Label/hackaton.git","metadata":{"id":"5oR2D2Us-xSQ","outputId":"7086cadf-a7fe-4d75-f271-6339bee8164d","papermill":{"duration":4.049235,"end_time":"2025-05-21T16:23:28.415556","exception":false,"start_time":"2025-05-21T16:23:24.366321","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T17:15:41.986115Z","iopub.execute_input":"2025-05-26T17:15:41.986407Z","iopub.status.idle":"2025-05-26T17:15:41.992455Z","shell.execute_reply.started":"2025-05-26T17:15:41.986367Z","shell.execute_reply":"2025-05-26T17:15:41.991470Z"}},"outputs":[],"execution_count":2},{"id":"c129091c","cell_type":"code","source":"# %cd hackaton/","metadata":{"id":"tEhfPly6-7UK","outputId":"3078ee06-6312-4fca-f5f9-888fa628c80a","papermill":{"duration":0.013251,"end_time":"2025-05-21T16:23:28.434119","exception":false,"start_time":"2025-05-21T16:23:28.420868","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T17:15:41.994863Z","iopub.execute_input":"2025-05-26T17:15:41.995122Z","iopub.status.idle":"2025-05-26T17:15:42.007763Z","shell.execute_reply.started":"2025-05-26T17:15:41.995103Z","shell.execute_reply":"2025-05-26T17:15:42.006812Z"}},"outputs":[],"execution_count":3},{"id":"d48103c0","cell_type":"code","source":"# !gdown --folder https://drive.google.com/drive/folders/1Z-1JkPJ6q4C6jX4brvq1VRbJH5RPUCAk -O datasets","metadata":{"id":"PxBvwB0_6xI8","outputId":"5933387c-2cfb-474f-d842-f36a3e2d2a73","papermill":{"duration":83.957666,"end_time":"2025-05-21T16:24:52.396720","exception":false,"start_time":"2025-05-21T16:23:28.439054","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T17:15:42.008780Z","iopub.execute_input":"2025-05-26T17:15:42.009086Z","iopub.status.idle":"2025-05-26T17:15:42.023949Z","shell.execute_reply.started":"2025-05-26T17:15:42.009060Z","shell.execute_reply":"2025-05-26T17:15:42.023009Z"}},"outputs":[],"execution_count":4},{"id":"80dab1bc","cell_type":"code","source":"# !ls -lh datasets","metadata":{"id":"1rockhiQ7Nny","outputId":"2cd2e6f4-5f8f-4a62-f0ec-53e6fc78c9b7","papermill":{"duration":0.138969,"end_time":"2025-05-21T16:24:52.549260","exception":false,"start_time":"2025-05-21T16:24:52.410291","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T17:15:42.024976Z","iopub.execute_input":"2025-05-26T17:15:42.025319Z","iopub.status.idle":"2025-05-26T17:15:42.040286Z","shell.execute_reply.started":"2025-05-26T17:15:42.025297Z","shell.execute_reply":"2025-05-26T17:15:42.039290Z"}},"outputs":[],"execution_count":5},{"id":"817b1078","cell_type":"code","source":"import os\nimport sys\nimport torch\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport logging\nfrom tqdm import tqdm\nfrom torch_geometric.loader import DataLoader\nfrom torch.utils.data import random_split\nimport argparse","metadata":{"id":"lAQuCuIoBbq5","papermill":{"duration":9.949638,"end_time":"2025-05-21T16:25:02.510764","exception":false,"start_time":"2025-05-21T16:24:52.561126","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T17:15:42.041469Z","iopub.execute_input":"2025-05-26T17:15:42.041751Z","iopub.status.idle":"2025-05-26T17:15:53.010232Z","shell.execute_reply.started":"2025-05-26T17:15:42.041728Z","shell.execute_reply":"2025-05-26T17:15:53.009353Z"}},"outputs":[],"execution_count":6},{"id":"08bedc6f-2af6-428f-a7db-c00a24038b98","cell_type":"code","source":"helper_scripts_path = '/kaggle/input/d/leonardosandri/myhackatonhelperscripts/'\n\nif os.path.exists(helper_scripts_path):\n    # Add this path to the beginning of Python's search list\n    sys.path.insert(0, helper_scripts_path)\n    print(f\"Successfully added '{helper_scripts_path}' to sys.path.\")\n    print(f\"Contents of '{helper_scripts_path}': {os.listdir(helper_scripts_path)}\") # Verify\nelse:\n    print(f\"WARNING: Helper scripts path not found: {helper_scripts_path}\")\n    print(\"Please ensure 'myhackathonhelperscripts' dataset is correctly added to the notebook.\")\n\n# Start import of utils modules\ntry:\n    from preprocessor import MultiDatasetLoader\n    from utils import set_seed\n    # from conv import GINConv as OriginalRepoGINConv\n    from models import GNN\n    print(\"Successfully imported modules.\")\nexcept ImportError as e:\n    print(f\"ERROR importing module: {e}\")\n    print(\"Please check that the .py files exist directly under the helper_scripts_path and have no syntax errors.\")\n    # print(\"Current sys.path:\", sys.path)\n\n# Set the random seed\nset_seed()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T17:15:53.011728Z","iopub.execute_input":"2025-05-26T17:15:53.012280Z","iopub.status.idle":"2025-05-26T17:15:53.936720Z","shell.execute_reply.started":"2025-05-26T17:15:53.012252Z","shell.execute_reply":"2025-05-26T17:15:53.935771Z"}},"outputs":[{"name":"stdout","text":"Successfully added '/kaggle/input/d/leonardosandri/myhackatonhelperscripts/' to sys.path.\nContents of '/kaggle/input/d/leonardosandri/myhackatonhelperscripts/': ['zipthefolder.py', 'loadData.py', 'utils.py', 'models.py', 'conv.py', 'preprocessor.py', '__init__.py']\nSuccessfully imported modules.\n","output_type":"stream"}],"execution_count":7},{"id":"f544afa5","cell_type":"markdown","source":"## 2. Data Preprocessing Functions\n","metadata":{}},{"id":"0a9c70d7","cell_type":"code","source":"def add_zeros(data):\n    data.x = torch.zeros(data.num_nodes, dtype=torch.long)\n    return data","metadata":{"id":"Dyf0I2-t9IcW","papermill":{"duration":0.019268,"end_time":"2025-05-21T16:25:02.544583","exception":false,"start_time":"2025-05-21T16:25:02.525315","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T17:15:53.937601Z","iopub.execute_input":"2025-05-26T17:15:53.938045Z","iopub.status.idle":"2025-05-26T17:15:53.942623Z","shell.execute_reply.started":"2025-05-26T17:15:53.938024Z","shell.execute_reply":"2025-05-26T17:15:53.941558Z"}},"outputs":[],"execution_count":8},{"id":"f0944127","cell_type":"markdown","source":"## 3. Training and Evaluation Functions","metadata":{}},{"id":"3622cfa1","cell_type":"code","source":"def train(data_loader, model, optimizer, criterion, device, save_checkpoints, checkpoint_path, current_epoch):\n    model.train()\n    total_loss = 0\n    correct = 0\n    total = 0\n    for data in tqdm(data_loader, desc=\"Iterating training graphs\", unit=\"batch\"):\n        data = data.to(device)\n        optimizer.zero_grad()\n        try:\n            output = model(data)\n        except IndexError as e:\n            print(f\"Error in batch with {data.num_nodes} nodes, edge_max={data.edge_index.max()}\")\n            print(f\"Batch info: x.shape={data.x.shape}, edge_index.shape={data.edge_index.shape}\")\n            raise e\n        loss = criterion(output, data.y)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n        pred = output.argmax(dim=1)\n        correct += (pred == data.y).sum().item()\n        total += data.y.size(0)\n\n    # Save checkpoints if required\n    if save_checkpoints:\n        checkpoint_file = f\"{checkpoint_path}_epoch_{current_epoch + 1}.pth\"\n        torch.save(model.state_dict(), checkpoint_file)\n        print(f\"Checkpoint saved at {checkpoint_file}\")\n\n    return total_loss / len(data_loader),  correct / total","metadata":{"id":"3jKvoQYI9Zbc","papermill":{"duration":0.019599,"end_time":"2025-05-21T16:25:02.577661","exception":false,"start_time":"2025-05-21T16:25:02.558062","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T17:15:53.945707Z","iopub.execute_input":"2025-05-26T17:15:53.945950Z","iopub.status.idle":"2025-05-26T17:15:53.958003Z","shell.execute_reply.started":"2025-05-26T17:15:53.945933Z","shell.execute_reply":"2025-05-26T17:15:53.957189Z"}},"outputs":[],"execution_count":9},{"id":"6139b912","cell_type":"code","source":"def evaluate(data_loader, model, device, calculate_accuracy=False):\n    model.eval()\n    correct = 0\n    total = 0\n    predictions = []\n    total_loss = 0\n    criterion = torch.nn.CrossEntropyLoss()\n    with torch.no_grad():\n        for data in tqdm(data_loader, desc=\"Iterating eval graphs\", unit=\"batch\"):\n            data = data.to(device)\n            output = model(data)\n            pred = output.argmax(dim=1)\n            \n            if calculate_accuracy:\n                correct += (pred == data.y).sum().item()\n                total += data.y.size(0)\n                total_loss += criterion(output, data.y).item()\n            else:\n                predictions.extend(pred.cpu().numpy())\n    if calculate_accuracy:\n        accuracy = correct / total\n        return  total_loss / len(data_loader),accuracy\n    return predictions","metadata":{"id":"8peFiIS19ZpK","papermill":{"duration":0.017908,"end_time":"2025-05-21T16:25:02.607848","exception":false,"start_time":"2025-05-21T16:25:02.589940","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T17:15:53.958859Z","iopub.execute_input":"2025-05-26T17:15:53.959298Z","iopub.status.idle":"2025-05-26T17:15:53.975771Z","shell.execute_reply.started":"2025-05-26T17:15:53.959279Z","shell.execute_reply":"2025-05-26T17:15:53.974812Z"}},"outputs":[],"execution_count":10},{"id":"26bba939","cell_type":"markdown","source":"## 4. Utility Functions","metadata":{}},{"id":"fbdbd871","cell_type":"code","source":"def save_predictions(predictions, test_path):\n    script_dir = os.getcwd() \n    submission_folder = os.path.join(script_dir, \"submission\")\n    test_dir_name = os.path.basename(os.path.dirname(test_path))\n    \n    os.makedirs(submission_folder, exist_ok=True)\n    \n    output_csv_path = os.path.join(submission_folder, f\"testset_{test_dir_name}.csv\")\n    \n    test_graph_ids = list(range(len(predictions)))\n    output_df = pd.DataFrame({\n        \"id\": test_graph_ids,\n        \"pred\": predictions\n    })\n    \n    output_df.to_csv(output_csv_path, index=False)\n    print(f\"Predictions saved to {output_csv_path}\")","metadata":{"id":"WanuZKxy9Zs-","papermill":{"duration":0.016728,"end_time":"2025-05-21T16:25:02.635694","exception":false,"start_time":"2025-05-21T16:25:02.618966","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T17:15:53.976665Z","iopub.execute_input":"2025-05-26T17:15:53.976888Z","iopub.status.idle":"2025-05-26T17:15:53.986006Z","shell.execute_reply.started":"2025-05-26T17:15:53.976872Z","shell.execute_reply":"2025-05-26T17:15:53.985139Z"}},"outputs":[],"execution_count":11},{"id":"fc3d24da","cell_type":"code","source":"def plot_training_progress(train_losses, train_accuracies, output_dir):\n    epochs = range(1, len(train_losses) + 1)\n    plt.figure(figsize=(12, 6))\n\n    # Plot loss\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, train_losses, label=\"Training Loss\", color='blue')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.title('Training Loss per Epoch')\n\n    # Plot accuracy\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, train_accuracies, label=\"Training Accuracy\", color='green')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.title('Training Accuracy per Epoch')\n\n    # Save plots in the current directory\n    os.makedirs(output_dir, exist_ok=True)\n    plt.tight_layout()\n    plt.savefig(os.path.join(output_dir, \"training_progress.png\"))\n    plt.close()","metadata":{"id":"uyHIJS5U9ZzB","papermill":{"duration":0.017765,"end_time":"2025-05-21T16:25:02.664538","exception":false,"start_time":"2025-05-21T16:25:02.646773","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T17:15:53.986931Z","iopub.execute_input":"2025-05-26T17:15:53.987172Z","iopub.status.idle":"2025-05-26T17:15:54.005511Z","shell.execute_reply.started":"2025-05-26T17:15:53.987155Z","shell.execute_reply":"2025-05-26T17:15:54.004647Z"}},"outputs":[],"execution_count":12},{"id":"0864fa6c","cell_type":"markdown","source":"## 5. Configuration and Arguments","metadata":{}},{"id":"22574fa5","cell_type":"code","source":"def get_user_input(prompt, default=None, required=False, type_cast=str):\n\n    while True:\n        user_input = input(f\"{prompt} [{default}]: \")\n        \n        if user_input == \"\" and required:\n            print(\"This field is required. Please enter a value.\")\n            continue\n        \n        if user_input == \"\" and default is not None:\n            return default\n        \n        if user_input == \"\" and not required:\n            return None\n        \n        try:\n            return type_cast(user_input)\n        except ValueError:\n            print(f\"Invalid input. Please enter a valid {type_cast.__name__}.\")","metadata":{"papermill":{"duration":0.016577,"end_time":"2025-05-21T16:25:02.692205","exception":false,"start_time":"2025-05-21T16:25:02.675628","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T17:15:54.006337Z","iopub.execute_input":"2025-05-26T17:15:54.006633Z","iopub.status.idle":"2025-05-26T17:15:54.022395Z","shell.execute_reply.started":"2025-05-26T17:15:54.006615Z","shell.execute_reply":"2025-05-26T17:15:54.021103Z"}},"outputs":[],"execution_count":13},{"id":"139e88b2","cell_type":"code","source":"def get_arguments():\n    \"\"\"Set training configuration directly\"\"\"\n    args = {\n        # Dataset selection\n        'dataset': 'A',  # Choose: A, B, C, D\n        'train_mode': 1,  # 1=single dataset, 2=all datasets\n        \n        # Model config\n        'gnn': 'gin',  # gin, gin-virtual, gcn, gcn-virtual\n        'drop_ratio': 0.0,\n        'num_layer': 5,\n        'emb_dim': 300,\n        \n        # Training config\n        'batch_size': 32,\n        'epochs': 10,\n        'baseline_mode': 1,  # 1=CE, 2=Noisy CE\n        'noise_prob': 0.2,\n        \n        # System config\n        'device': 0,\n        'num_checkpoints': 3\n    }\n    return argparse.Namespace(**args)","metadata":{"papermill":{"duration":0.017703,"end_time":"2025-05-21T16:25:02.721184","exception":false,"start_time":"2025-05-21T16:25:02.703481","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T17:15:54.023488Z","iopub.execute_input":"2025-05-26T17:15:54.024010Z","iopub.status.idle":"2025-05-26T17:15:54.036672Z","shell.execute_reply.started":"2025-05-26T17:15:54.023987Z","shell.execute_reply":"2025-05-26T17:15:54.035978Z"}},"outputs":[],"execution_count":14},{"id":"45bffa19","cell_type":"code","source":"def populate_args(args):\n    print(\"Arguments received:\")\n    for key, value in vars(args).items():\n        print(f\"{key}: {value}\")\nargs = get_arguments()\npopulate_args(args)","metadata":{"papermill":{"duration":0.118164,"end_time":"2025-05-21T16:25:02.850799","exception":true,"start_time":"2025-05-21T16:25:02.732635","status":"failed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T17:15:54.037571Z","iopub.execute_input":"2025-05-26T17:15:54.037944Z","iopub.status.idle":"2025-05-26T17:15:54.074987Z","shell.execute_reply.started":"2025-05-26T17:15:54.037918Z","shell.execute_reply":"2025-05-26T17:15:54.073720Z"}},"outputs":[{"name":"stdout","text":"Arguments received:\ndataset: A\ntrain_mode: 1\ngnn: gin\ndrop_ratio: 0.0\nnum_layer: 5\nemb_dim: 300\nbatch_size: 32\nepochs: 10\nbaseline_mode: 1\nnoise_prob: 0.2\ndevice: 0\nnum_checkpoints: 3\n","output_type":"stream"}],"execution_count":15},{"id":"d40170fe","cell_type":"markdown","source":"## 6. Loss Function Definition","metadata":{}},{"id":"09b57d62","cell_type":"code","source":"class NoisyCrossEntropyLoss(torch.nn.Module):\n    def __init__(self, p_noisy):\n        super().__init__()\n        self.p = p_noisy\n        self.ce = torch.nn.CrossEntropyLoss(reduction='none')\n\n    def forward(self, logits, targets):\n        losses = self.ce(logits, targets)\n        weights = (1 - self.p) + self.p * (1 - torch.nn.functional.one_hot(targets, num_classes=logits.size(1)).float().sum(dim=1))\n        return (losses * weights).mean()","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T17:15:54.075947Z","iopub.execute_input":"2025-05-26T17:15:54.076235Z","iopub.status.idle":"2025-05-26T17:15:54.089749Z","shell.execute_reply.started":"2025-05-26T17:15:54.076215Z","shell.execute_reply":"2025-05-26T17:15:54.088703Z"}},"outputs":[],"execution_count":16},{"id":"e319a162","cell_type":"markdown","source":"## 7. Main training pipeline","metadata":{}},{"id":"a210abf8","cell_type":"markdown","source":"### 7.1 Config section\n","metadata":{}},{"id":"24a82d11","cell_type":"code","source":"print(\"=\" * 60)\nprint(\"Enhanced GNN Training Pipeline\")\nprint(\"=\" * 60)\n\n# Get configuration\nargs = get_arguments()\n\nprint(\"\\nConfiguration:\")\nfor key, value in vars(args).items():\n    print(f\"  {key}: {value}\")\n\n# Setup device\ndevice = torch.device(f\"cuda:{args.device}\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"\\nUsing device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T17:15:54.090668Z","iopub.execute_input":"2025-05-26T17:15:54.090913Z","iopub.status.idle":"2025-05-26T17:15:54.105696Z","shell.execute_reply.started":"2025-05-26T17:15:54.090884Z","shell.execute_reply":"2025-05-26T17:15:54.104790Z"}},"outputs":[{"name":"stdout","text":"============================================================\nEnhanced GNN Training Pipeline\n============================================================\n\nConfiguration:\n  dataset: A\n  train_mode: 1\n  gnn: gin\n  drop_ratio: 0.0\n  num_layer: 5\n  emb_dim: 300\n  batch_size: 32\n  epochs: 10\n  baseline_mode: 1\n  noise_prob: 0.2\n  device: 0\n  num_checkpoints: 3\n\nUsing device: cpu\n","output_type":"stream"}],"execution_count":17},{"id":"26506118","cell_type":"markdown","source":"### 7.2 Data Loading","metadata":{}},{"id":"81432ff3","cell_type":"code","source":"print(\"\\n\" + \"=\"*40)\nprint(\"LOADING DATA\")\nprint(\"=\"*40)\n\nbase_path = '/kaggle/input/deep-dataset-preprocessed/processed_data_separate'\n\n# Prepare training/validation data based on mode\nif args.train_mode == 1:\n    # Single dataset mode\n    dataset_name = args.dataset\n    train_dataset = torch.load(f'{base_path}/{dataset_name}_train_graphs.pt', weights_only=False)\n    train_dataset = [add_zeros(data) for data in train_dataset]\n    \n    val_dataset = torch.load(f'{base_path}/{dataset_name}_val_graphs.pt', weights_only=False)\n    val_dataset = [add_zeros(data) for data in val_dataset]\n    \n    test_dataset = torch.load(f'{base_path}/{dataset_name}_test_graphs.pt', weights_only=False)\n    test_dataset = [add_zeros(data) for data in test_dataset]\n    print(f\"Using single dataset: {dataset_name}\")\nelse:\n    # All datasets mode\n    train_dataset = []\n    val_dataset = []\n    test_dataset = torch.load(f'{base_path}/{args.dataset}_test_graphs.pt', weights_only=False)  # Test on specified dataset\n    \n    for ds_name in ['A', 'B', 'C', 'D']:\n        train_dataset.extend(torch.load(f'{base_path}/{ds_name}_train_graphs.pt', weights_only=False))\n        val_dataset.extend(torch.load(f'{base_path}/{ds_name}_val_graphs.pt', weights_only=False))\n    \n    print(\"Using all datasets for training\")\n\nprint(f\"Train samples: {len(train_dataset)}\")\nprint(f\"Val samples: {len(val_dataset)}\")\nprint(f\"Test samples: {len(test_dataset)}\")\n\n# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=0)\nval_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False, num_workers=0)\ntest_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, num_workers=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T17:15:54.106660Z","iopub.execute_input":"2025-05-26T17:15:54.106940Z","iopub.status.idle":"2025-05-26T17:16:18.832079Z","shell.execute_reply.started":"2025-05-26T17:15:54.106916Z","shell.execute_reply":"2025-05-26T17:16:18.831192Z"}},"outputs":[{"name":"stdout","text":"\n========================================\nLOADING DATA\n========================================\nUsing single dataset: A\nTrain samples: 10152\nVal samples: 1128\nTest samples: 2340\n","output_type":"stream"}],"execution_count":18},{"id":"63613e69","cell_type":"markdown","source":"### 7.3 Model Setup","metadata":{}},{"id":"269b5bb3","cell_type":"code","source":"\nprint(\"\\n\" + \"=\"*40)\nprint(\"MODEL SETUP\")\nprint(\"=\"*40)\n\n# Initialize model\nif args.gnn == 'gin':\n    model = GNN(gnn_type='gin', num_class=6, num_layer=args.num_layer, \n               emb_dim=args.emb_dim, drop_ratio=args.drop_ratio, virtual_node=False)\nelif args.gnn == 'gin-virtual':\n    model = GNN(gnn_type='gin', num_class=6, num_layer=args.num_layer,\n               emb_dim=args.emb_dim, drop_ratio=args.drop_ratio, virtual_node=True)\nelif args.gnn == 'gcn':\n    model = GNN(gnn_type='gcn', num_class=6, num_layer=args.num_layer,\n               emb_dim=args.emb_dim, drop_ratio=args.drop_ratio, virtual_node=False)\nelif args.gnn == 'gcn-virtual':\n    model = GNN(gnn_type='gcn', num_class=6, num_layer=args.num_layer,\n               emb_dim=args.emb_dim, drop_ratio=args.drop_ratio, virtual_node=True)\nelse:\n    raise ValueError(f'Invalid GNN type: {args.gnn}')\n\nmodel = model.to(device)\n\n# Setup optimizer and loss\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\nif args.baseline_mode == 2:\n    criterion = NoisyCrossEntropyLoss(args.noise_prob)\n    print(f\"Using Noisy Cross Entropy Loss (p={args.noise_prob})\")\nelse:\n    criterion = torch.nn.CrossEntropyLoss()\n    print(\"Using standard Cross Entropy Loss\")\n\nprint(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n\n# Setup logging and checkpoints\nexp_name = f\"{args.gnn}_dataset{args.dataset}_mode{args.train_mode}\"\nlogs_dir = os.path.join(\"logs\", exp_name)\ncheckpoints_dir = os.path.join(\"checkpoints\", exp_name)\nos.makedirs(logs_dir, exist_ok=True)\nos.makedirs(checkpoints_dir, exist_ok=True)\n\n# Setup logging\nlog_file = os.path.join(logs_dir, \"training.log\")\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(message)s',\n    handlers=[\n        logging.FileHandler(log_file),\n        logging.StreamHandler()\n    ]\n)\n\nbest_model_path = os.path.join(checkpoints_dir, \"best_model.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T17:16:18.833034Z","iopub.execute_input":"2025-05-26T17:16:18.833331Z","iopub.status.idle":"2025-05-26T17:16:18.929984Z","shell.execute_reply.started":"2025-05-26T17:16:18.833307Z","shell.execute_reply":"2025-05-26T17:16:18.928989Z"}},"outputs":[{"name":"stdout","text":"\n========================================\nMODEL SETUP\n========================================\nUsing standard Cross Entropy Loss\nModel parameters: 1,827,611\n","output_type":"stream"}],"execution_count":19},{"id":"25032fa3","cell_type":"markdown","source":"### 7.4 Training loop\n","metadata":{}},{"id":"ad0e3701","cell_type":"code","source":"print(\"\\n\" + \"=\"*40)\nprint(\"TRAINING\")\nprint(\"=\"*40)\n\nbest_val_accuracy = 0.0\ntrain_losses = []\ntrain_accuracies = []\nval_losses = []\nval_accuracies = []\n\n# Calculate checkpoint intervals\nif args.num_checkpoints > 1:\n    checkpoint_intervals = [int((i + 1) * args.epochs / args.num_checkpoints) \n                          for i in range(args.num_checkpoints)]\nelse:\n    checkpoint_intervals = [args.epochs]\n\nfor epoch in range(args.epochs):\n    print(f\"\\nEpoch {epoch + 1}/{args.epochs}\")\n    print(\"-\" * 30)\n    \n    # Training\n    train_loss, train_acc = train(\n        train_loader, model, optimizer, criterion, device,\n        save_checkpoints=(epoch + 1 in checkpoint_intervals),\n        checkpoint_path=os.path.join(checkpoints_dir, \"checkpoint\"),\n        current_epoch=epoch\n    )\n    \n    # Validation\n    val_loss, val_acc = evaluate(val_loader, model, device, calculate_accuracy=True)\n    \n    # Log results\n    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n    \n    logging.info(f\"Epoch {epoch + 1}: Train Loss={train_loss:.4f}, Train Acc={train_acc:.4f}, \"\n                f\"Val Loss={val_loss:.4f}, Val Acc={val_acc:.4f}\")\n    \n    # Store metrics\n    train_losses.append(train_loss)\n    train_accuracies.append(train_acc)\n    val_losses.append(val_loss)\n    val_accuracies.append(val_acc)\n    \n    # Save best model\n    if val_acc > best_val_accuracy:\n        best_val_accuracy = val_acc\n        torch.save(model.state_dict(), best_model_path)\n        print(f\"★ New best model saved! Val Acc: {val_acc:.4f}\")\n\nprint(f\"\\nBest validation accuracy: {best_val_accuracy:.4f}\")\n\n# Plot training progress\nplot_training_progress(train_losses, train_accuracies, val_losses, val_accuracies, logs_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T17:16:18.931112Z","iopub.execute_input":"2025-05-26T17:16:18.931598Z"}},"outputs":[{"name":"stdout","text":"\n========================================\nTRAINING\n========================================\n\nEpoch 1/10\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs:   7%|▋         | 22/318 [01:43<23:45,  4.82s/batch]","output_type":"stream"}],"execution_count":null},{"id":"13ece3f6-dd29-4f6d-beb0-c4295bf32074","cell_type":"code","source":"# Test DataLoader batching directly\nfor batch in train_loader:\n    print(f\"DataLoader batch: x={batch.x.shape}, edge_max={batch.edge_index.max()}\")\n    if batch.x.shape[0] <= batch.edge_index.max():\n        print(\"FOUND CORRUPTED BATCH!\")\n    break","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"25604a74","cell_type":"markdown","source":"### 7.5 Testing and predictions","metadata":{}},{"id":"de27e926","cell_type":"code","source":"print(\"\\n\" + \"=\"*40)\nprint(\"TESTING\")\nprint(\"=\"*40)\n\n# Load best model and make predictions\nmodel.load_state_dict(torch.load(best_model_path))\nprint(f\"Loaded best model from: {best_model_path}\")\n\npredictions = evaluate(test_loader, model, device, calculate_accuracy=False)\n\n# Save predictions\nsave_predictions(predictions, args.dataset)\n\n# Cleanup\ndel train_dataset, val_dataset, test_dataset\ndel train_loader, val_loader, test_loader\ngc.collect()\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"TRAINING COMPLETED SUCCESSFULLY!\")\nprint(\"=\"*60)\nprint(f\"Best validation accuracy: {best_val_accuracy:.4f}\")\nprint(f\"Predictions saved for dataset {args.dataset}\")\nprint(f\"Logs and plots saved in: {logs_dir}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"be039b0e-005f-4884-b31e-b5d364a2529d","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"dcc0e197-332f-4f35-9901-011b14a4dfd0","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}