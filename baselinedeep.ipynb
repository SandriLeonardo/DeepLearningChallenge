{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11958675,"sourceType":"datasetVersion","datasetId":7519186},{"sourceId":11986724,"sourceType":"datasetVersion","datasetId":7519473}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":108.457758,"end_time":"2025-05-21T16:25:04.482169","environment_variables":{},"exception":true,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-05-21T16:23:16.024411","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Graph Neural Network Training Pipeline","metadata":{}},{"cell_type":"markdown","source":"Multi-Dataset Graph Classification with Noise-Robust Training","metadata":{}},{"cell_type":"markdown","source":"## 1. Setup and Dependencies","metadata":{}},{"cell_type":"code","source":"!pip install torch_geometric","metadata":{"id":"xSkgt1zf-raF","outputId":"59f4a52f-5eb4-41e5-9fba-07432989fe78","papermill":{"duration":5.620104,"end_time":"2025-05-21T16:23:24.36169","exception":false,"start_time":"2025-05-21T16:23:18.741586","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T18:00:30.377764Z","iopub.execute_input":"2025-05-28T18:00:30.378061Z","iopub.status.idle":"2025-05-28T18:00:35.708646Z","shell.execute_reply.started":"2025-05-28T18:00:30.378027Z","shell.execute_reply":"2025-05-28T18:00:35.707967Z"}},"outputs":[{"name":"stdout","text":"Collecting torch_geometric\n  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.18)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (7.0.0)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.0.9)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.20.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.4.26)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch_geometric) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch_geometric) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torch_geometric) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torch_geometric) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torch_geometric) (2024.2.0)\nDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torch_geometric\nSuccessfully installed torch_geometric-2.6.1\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import os\nimport gc\nimport sys\nimport torch\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport logging\nfrom tqdm import tqdm\nfrom torch_geometric.loader import DataLoader\nfrom torch.utils.data import random_split\nimport argparse","metadata":{"id":"lAQuCuIoBbq5","papermill":{"duration":9.949638,"end_time":"2025-05-21T16:25:02.510764","exception":false,"start_time":"2025-05-21T16:24:52.561126","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T18:00:35.710121Z","iopub.execute_input":"2025-05-28T18:00:35.710382Z","iopub.status.idle":"2025-05-28T18:00:45.674107Z","shell.execute_reply.started":"2025-05-28T18:00:35.710358Z","shell.execute_reply":"2025-05-28T18:00:45.673541Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"helper_scripts_path = '/kaggle/input/d/leonardosandri/myhackatonhelperscripts/'\n\nif os.path.exists(helper_scripts_path):\n    # Add this path to the beginning of Python's search list\n    sys.path.insert(0, helper_scripts_path)\n    print(f\"Successfully added '{helper_scripts_path}' to sys.path.\")\n    print(f\"Contents of '{helper_scripts_path}': {os.listdir(helper_scripts_path)}\") # Verify\nelse:\n    print(f\"WARNING: Helper scripts path not found: {helper_scripts_path}\")\n    print(\"Please ensure 'myhackathonhelperscripts' dataset is correctly added to the notebook.\")\n\n# Start import of utils modules\ntry:\n    from preprocessor import MultiDatasetLoader\n    from utils import set_seed\n    # from conv import GINConv as OriginalRepoGINConv\n    from models_EDandBatch_norm import GNN\n    print(\"Successfully imported modules.\")\nexcept ImportError as e:\n    print(f\"ERROR importing module: {e}\")\n    print(\"Please check that the .py files exist directly under the helper_scripts_path and have no syntax errors.\")\n    # print(\"Current sys.path:\", sys.path)\n\n# Set the random seed\nset_seed()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T18:00:45.674764Z","iopub.execute_input":"2025-05-28T18:00:45.675134Z","iopub.status.idle":"2025-05-28T18:00:46.406636Z","shell.execute_reply.started":"2025-05-28T18:00:45.675107Z","shell.execute_reply":"2025-05-28T18:00:46.406047Z"}},"outputs":[{"name":"stdout","text":"Successfully added '/kaggle/input/d/leonardosandri/myhackatonhelperscripts/' to sys.path.\nContents of '/kaggle/input/d/leonardosandri/myhackatonhelperscripts/': ['models_edge_drop.py', 'zipthefolder.py', 'loadData.py', 'utils.py', 'models_EDandBatch_norm.py', 'models.py', 'conv.py', 'preprocessor.py', '__init__.py']\nSuccessfully imported modules.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## 2. Data Preprocessing Functions\n","metadata":{}},{"cell_type":"code","source":"def add_zeros(data):\n    data.x = torch.zeros(data.num_nodes, dtype=torch.long)\n    return data","metadata":{"id":"Dyf0I2-t9IcW","papermill":{"duration":0.019268,"end_time":"2025-05-21T16:25:02.544583","exception":false,"start_time":"2025-05-21T16:25:02.525315","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T18:00:46.408314Z","iopub.execute_input":"2025-05-28T18:00:46.409067Z","iopub.status.idle":"2025-05-28T18:00:46.412383Z","shell.execute_reply.started":"2025-05-28T18:00:46.409045Z","shell.execute_reply":"2025-05-28T18:00:46.411714Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## 3. Training and Evaluation Functions","metadata":{}},{"cell_type":"code","source":"def train(data_loader, model, optimizer, criterion, device, save_checkpoints, checkpoint_path, current_epoch):\n    model.train()\n    total_loss = 0\n    correct = 0\n    total = 0\n    for data in tqdm(data_loader, desc=\"Iterating training graphs\", unit=\"batch\"):\n        data = data.to(device)\n        optimizer.zero_grad()\n        try:\n            output = model(data)\n        except IndexError as e:\n            print(f\"Error in batch with {data.num_nodes} nodes, edge_max={data.edge_index.max()}\")\n            print(f\"Batch info: x.shape={data.x.shape}, edge_index.shape={data.edge_index.shape}\")\n            raise e\n        loss = criterion(output, data.y)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n        pred = output.argmax(dim=1)\n        correct += (pred == data.y).sum().item()\n        total += data.y.size(0)\n\n    # Save checkpoints if required\n    if save_checkpoints:\n        checkpoint_file = f\"{checkpoint_path}_epoch_{current_epoch + 1}.pth\"\n        torch.save(model.state_dict(), checkpoint_file)\n        print(f\"Checkpoint saved at {checkpoint_file}\")\n\n    return total_loss / len(data_loader),  correct / total","metadata":{"id":"3jKvoQYI9Zbc","papermill":{"duration":0.019599,"end_time":"2025-05-21T16:25:02.577661","exception":false,"start_time":"2025-05-21T16:25:02.558062","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T18:00:46.413173Z","iopub.execute_input":"2025-05-28T18:00:46.413448Z","iopub.status.idle":"2025-05-28T18:00:46.429599Z","shell.execute_reply.started":"2025-05-28T18:00:46.413423Z","shell.execute_reply":"2025-05-28T18:00:46.428883Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# CELL 7 (Corrected)\ndef evaluate(data_loader, model, criterion, device, calculate_accuracy=False): # Added 'criterion' argument\n    model.eval()\n    correct = 0\n    total = 0\n    predictions = []\n    total_loss = 0\n    # REMOVE THE HARDCODED CRITERION:\n    # criterion = torch.nn.CrossEntropyLoss()\n\n    with torch.no_grad():\n        for data in tqdm(data_loader, desc=\"Iterating eval graphs\", unit=\"batch\"):\n            data = data.to(device)\n            output = model(data)\n            pred = output.argmax(dim=1)\n\n            if calculate_accuracy:\n                correct += (pred == data.y).sum().item()\n                total += data.y.size(0)\n                # NOW USES THE PASSED-IN CRITERION\n                total_loss += criterion(output, data.y).item()\n            else:\n                predictions.extend(pred.cpu().numpy())\n    if calculate_accuracy:\n        accuracy = correct / total\n        return  total_loss / len(data_loader), accuracy # Ensure consistent return order\n    return predictions","metadata":{"id":"8peFiIS19ZpK","papermill":{"duration":0.017908,"end_time":"2025-05-21T16:25:02.607848","exception":false,"start_time":"2025-05-21T16:25:02.58994","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T18:00:46.430421Z","iopub.execute_input":"2025-05-28T18:00:46.431302Z","iopub.status.idle":"2025-05-28T18:00:46.451885Z","shell.execute_reply.started":"2025-05-28T18:00:46.431284Z","shell.execute_reply":"2025-05-28T18:00:46.451299Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## 4. Utility Functions","metadata":{}},{"cell_type":"code","source":"def save_predictions(predictions, test_path):\n    script_dir = os.getcwd() \n    submission_folder = os.path.join(script_dir, \"submission\")\n    test_dir_name = os.path.basename(os.path.dirname(test_path))\n    \n    os.makedirs(submission_folder, exist_ok=True)\n    \n    output_csv_path = os.path.join(submission_folder, f\"testset_{test_dir_name}.csv\")\n    \n    test_graph_ids = list(range(len(predictions)))\n    output_df = pd.DataFrame({\n        \"id\": test_graph_ids,\n        \"pred\": predictions\n    })\n    \n    output_df.to_csv(output_csv_path, index=False)\n    print(f\"Predictions saved to {output_csv_path}\")","metadata":{"id":"WanuZKxy9Zs-","papermill":{"duration":0.016728,"end_time":"2025-05-21T16:25:02.635694","exception":false,"start_time":"2025-05-21T16:25:02.618966","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T18:00:46.452469Z","iopub.execute_input":"2025-05-28T18:00:46.452628Z","iopub.status.idle":"2025-05-28T18:00:46.472162Z","shell.execute_reply.started":"2025-05-28T18:00:46.452615Z","shell.execute_reply":"2025-05-28T18:00:46.471625Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def plot_training_progress(train_losses, train_accuracies, val_losses, val_accuracies, output_dir):\n    \"\"\"\n    Plot training and validation progress over epochs.\n    \n    Args:\n        train_losses: List of training losses per epoch\n        train_accuracies: List of training accuracies per epoch  \n        val_losses: List of validation losses per epoch\n        val_accuracies: List of validation accuracies per epoch\n        output_dir: Directory to save the plot\n    \"\"\"\n    epochs = range(1, len(train_losses) + 1)\n    plt.figure(figsize=(15, 6))\n    \n    # Plot losses\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, train_losses, label=\"Training Loss\", color='blue', marker='o')\n    plt.plot(epochs, val_losses, label=\"Validation Loss\", color='red', marker='s')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.title('Training and Validation Loss per Epoch')\n    plt.legend()\n    plt.grid(True)\n    \n    # Plot accuracies\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, train_accuracies, label=\"Training Accuracy\", color='green', marker='o')\n    plt.plot(epochs, val_accuracies, label=\"Validation Accuracy\", color='orange', marker='s')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.title('Training and Validation Accuracy per Epoch')\n    plt.legend()\n    plt.grid(True)\n    \n    # Save plot\n    os.makedirs(output_dir, exist_ok=True)\n    plt.tight_layout()\n    plt.savefig(os.path.join(output_dir, \"training_progress.png\"))\n    plt.show()\n    plt.close()","metadata":{"id":"uyHIJS5U9ZzB","papermill":{"duration":0.017765,"end_time":"2025-05-21T16:25:02.664538","exception":false,"start_time":"2025-05-21T16:25:02.646773","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T18:00:46.472777Z","iopub.execute_input":"2025-05-28T18:00:46.472963Z","iopub.status.idle":"2025-05-28T18:00:46.489922Z","shell.execute_reply.started":"2025-05-28T18:00:46.472949Z","shell.execute_reply":"2025-05-28T18:00:46.489407Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## 5. Configuration and Arguments","metadata":{}},{"cell_type":"code","source":"def get_user_input(prompt, default=None, required=False, type_cast=str):\n\n    while True:\n        user_input = input(f\"{prompt} [{default}]: \")\n        \n        if user_input == \"\" and required:\n            print(\"This field is required. Please enter a value.\")\n            continue\n        \n        if user_input == \"\" and default is not None:\n            return default\n        \n        if user_input == \"\" and not required:\n            return None\n        \n        try:\n            return type_cast(user_input)\n        except ValueError:\n            print(f\"Invalid input. Please enter a valid {type_cast.__name__}.\")","metadata":{"papermill":{"duration":0.016577,"end_time":"2025-05-21T16:25:02.692205","exception":false,"start_time":"2025-05-21T16:25:02.675628","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T18:00:46.490637Z","iopub.execute_input":"2025-05-28T18:00:46.490848Z","iopub.status.idle":"2025-05-28T18:00:46.509647Z","shell.execute_reply.started":"2025-05-28T18:00:46.490833Z","shell.execute_reply":"2025-05-28T18:00:46.509051Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def get_arguments():\n    \"\"\"Set training configuration directly\"\"\"\n    args = {\n        # Dataset selection\n        'dataset': 'A',  # Choose: A, B, C, D\n        'train_mode': 1,  # 1=single dataset, 2=all datasets\n        \n        # Model config\n        #'gnn': 'gin',  # gin, gin-virtual, gcn, gcn-virtual\n        'num_layer': 3,\n        'emb_dim': 256,\n        'drop_ratio': 0.3,   # Dropout ratio\n        'virtual_node': True, # True to use virtual node, False otherwise\n        'residual': True,    # True to use residual connections, False otherwise\n        'JK': \"last\",         # Jumping Knowledge: \"last\", \"sum\", \"cat\"\n        'edge_drop_ratio' : 0.15,\n        'batch_norm' : True,\n        'graph_pooling': \"mean\", # \"sum\", \"mean\", \"max\", \"attention\", \"set2set\"\n        \n        # Training config\n        'batch_size': 64,\n        'epochs': 200,\n        'baseline_mode': 3,  # 1=CE, 2=Noisy CE, 3 GCE\n        'noise_prob': 0.2,\n        'gce_q' : 0.5,\n\n        # Early stopping config\n        'early_stopping': True,  # Enable/disable early stopping\n        'patience': 25,          # Number of epochs to wait without improvement\n        \n        # System config\n        'device': 0,\n        'num_checkpoints': 3,\n    }\n    return argparse.Namespace(**args)","metadata":{"papermill":{"duration":0.017703,"end_time":"2025-05-21T16:25:02.721184","exception":false,"start_time":"2025-05-21T16:25:02.703481","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T18:00:46.511758Z","iopub.execute_input":"2025-05-28T18:00:46.512181Z","iopub.status.idle":"2025-05-28T18:00:46.529333Z","shell.execute_reply.started":"2025-05-28T18:00:46.512166Z","shell.execute_reply":"2025-05-28T18:00:46.528442Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def populate_args(args):\n    print(\"Arguments received:\")\n    for key, value in vars(args).items():\n        print(f\"{key}: {value}\")\nargs = get_arguments()\npopulate_args(args)","metadata":{"papermill":{"duration":0.118164,"end_time":"2025-05-21T16:25:02.850799","exception":true,"start_time":"2025-05-21T16:25:02.732635","status":"failed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T18:00:46.530130Z","iopub.execute_input":"2025-05-28T18:00:46.530391Z","iopub.status.idle":"2025-05-28T18:00:46.546493Z","shell.execute_reply.started":"2025-05-28T18:00:46.530375Z","shell.execute_reply":"2025-05-28T18:00:46.545768Z"}},"outputs":[{"name":"stdout","text":"Arguments received:\ndataset: A\ntrain_mode: 1\nnum_layer: 3\nemb_dim: 256\ndrop_ratio: 0.3\nvirtual_node: True\nresidual: True\nJK: last\nedge_drop_ratio: 0.15\nbatch_norm: True\ngraph_pooling: mean\nbatch_size: 64\nepochs: 200\nbaseline_mode: 3\nnoise_prob: 0.2\ngce_q: 0.5\nearly_stopping: True\npatience: 25\ndevice: 0\nnum_checkpoints: 3\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"## 6. Loss Function Definition","metadata":{}},{"cell_type":"code","source":"class NoisyCrossEntropyLoss(torch.nn.Module):\n    def __init__(self, p_noisy):\n        super().__init__()\n        self.p = p_noisy\n        self.ce = torch.nn.CrossEntropyLoss(reduction='none')\n\n    def forward(self, logits, targets):\n        losses = self.ce(logits, targets)\n        weights = (1 - self.p) + self.p * (1 - torch.nn.functional.one_hot(targets, num_classes=logits.size(1)).float().sum(dim=1))\n        return (losses * weights).mean()","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T18:00:46.547649Z","iopub.execute_input":"2025-05-28T18:00:46.547898Z","iopub.status.idle":"2025-05-28T18:00:46.564330Z","shell.execute_reply.started":"2025-05-28T18:00:46.547874Z","shell.execute_reply":"2025-05-28T18:00:46.563651Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# CELL 12.1 (New Cell or append to existing cell 12)\nclass GeneralizedCrossEntropyLoss(torch.nn.Module):\n    def __init__(self, q=0.7):\n        \"\"\"\n        Generalized Cross Entropy Loss.\n        q is a hyperparameter, 0 < q <= 1.\n        As q -> 0, GCE approaches standard CE.\n        \"\"\"\n        super(GeneralizedCrossEntropyLoss, self).__init__()\n        if not (0 < q <= 1):\n            # While the limit q->0 is CE, for q=0 direct computation is 1/0.\n            # The paper usually uses q > 0.\n            raise ValueError(\"q should be in (0, 1]\")\n        self.q = q\n\n    def forward(self, logits, targets):\n        probs = torch.softmax(logits, dim=1)\n        # Select probabilities of the target class for each sample\n        target_probs = probs[torch.arange(targets.size(0)), targets]\n\n        # To prevent issues with target_probs being exactly 0,\n        # especially if q is very small (though here q > 0).\n        # However, 0^q is 0 for q > 0, so it should be fine.\n        # For extra safety: target_probs = target_probs.clamp(min=1e-8)\n\n        # GCE loss: (1 - p_t^q) / q\n        loss = (1 - (target_probs ** self.q)) / self.q\n        return loss.mean()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T18:00:46.565072Z","iopub.execute_input":"2025-05-28T18:00:46.565310Z","iopub.status.idle":"2025-05-28T18:00:46.579624Z","shell.execute_reply.started":"2025-05-28T18:00:46.565286Z","shell.execute_reply":"2025-05-28T18:00:46.579038Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"## 7. Model creation","metadata":{}},{"cell_type":"markdown","source":"### 7.1 Config section\n","metadata":{}},{"cell_type":"code","source":"print(\"=\" * 60)\nprint(\"Enhanced GNN Training Pipeline\")\nprint(\"=\" * 60)\n\n# Get configuration\nargs = get_arguments()\n\nprint(\"\\nConfiguration:\")\nfor key, value in vars(args).items():\n    print(f\"  {key}: {value}\")\n\n# Setup device\ndevice = torch.device(f\"cuda:{args.device}\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"\\nUsing device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T18:00:46.580226Z","iopub.execute_input":"2025-05-28T18:00:46.580384Z","iopub.status.idle":"2025-05-28T18:00:46.594363Z","shell.execute_reply.started":"2025-05-28T18:00:46.580372Z","shell.execute_reply":"2025-05-28T18:00:46.593692Z"}},"outputs":[{"name":"stdout","text":"============================================================\nEnhanced GNN Training Pipeline\n============================================================\n\nConfiguration:\n  dataset: A\n  train_mode: 1\n  num_layer: 3\n  emb_dim: 256\n  drop_ratio: 0.3\n  virtual_node: True\n  residual: True\n  JK: last\n  edge_drop_ratio: 0.15\n  batch_norm: True\n  graph_pooling: mean\n  batch_size: 64\n  epochs: 200\n  baseline_mode: 3\n  noise_prob: 0.2\n  gce_q: 0.5\n  early_stopping: True\n  patience: 25\n  device: 0\n  num_checkpoints: 3\n\nUsing device: cuda:0\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"### 7.2 Data Loading","metadata":{}},{"cell_type":"code","source":"print(\"\\n\" + \"=\"*40)\nprint(\"LOADING DATA\")\nprint(\"=\"*40)\n\nbase_path = '/kaggle/input/deep-dataset-preprocessed/processed_data_separate'\n\n# Prepare training/validation data based on mode\nif args.train_mode == 1:\n    # Single dataset mode\n    dataset_name = args.dataset\n    train_dataset = torch.load(f'{base_path}/{dataset_name}_train_graphs.pt', weights_only=False)\n    train_dataset = [add_zeros(data) for data in train_dataset]\n    \n    val_dataset = torch.load(f'{base_path}/{dataset_name}_val_graphs.pt', weights_only=False)\n    val_dataset = [add_zeros(data) for data in val_dataset]\n    \n    test_dataset = torch.load(f'{base_path}/{dataset_name}_test_graphs.pt', weights_only=False)\n    test_dataset = [add_zeros(data) for data in test_dataset]\n    print(f\"Using single dataset: {dataset_name}\")\nelse:\n    # All datasets mode\n    train_dataset = []\n    val_dataset = []\n    test_dataset = torch.load(f'{base_path}/{args.dataset}_test_graphs.pt', weights_only=False)  # Test on specified dataset\n    \n    for ds_name in ['A', 'B', 'C', 'D']:\n        train_dataset.extend(torch.load(f'{base_path}/{ds_name}_train_graphs.pt', weights_only=False))\n        val_dataset.extend(torch.load(f'{base_path}/{ds_name}_val_graphs.pt', weights_only=False))\n    \n    print(\"Using all datasets for training\")\n\nprint(f\"Train samples: {len(train_dataset)}\")\nprint(f\"Val samples: {len(val_dataset)}\")\nprint(f\"Test samples: {len(test_dataset)}\")\n\n# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=0)\nval_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False, num_workers=0)\ntest_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, num_workers=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T18:00:46.595111Z","iopub.execute_input":"2025-05-28T18:00:46.595315Z","iopub.status.idle":"2025-05-28T18:01:13.453350Z","shell.execute_reply.started":"2025-05-28T18:00:46.595292Z","shell.execute_reply":"2025-05-28T18:01:13.452737Z"}},"outputs":[{"name":"stdout","text":"\n========================================\nLOADING DATA\n========================================\nUsing single dataset: A\nTrain samples: 10152\nVal samples: 1128\nTest samples: 2340\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"### 7.3 Model Setup","metadata":{}},{"cell_type":"code","source":"\nprint(\"\\n\" + \"=\"*40)\nprint(\"MODEL SETUP\")\nprint(\"=\"*40)\n\n# Initialize model\nmodel = GNN(num_class=6, # Assuming 6 classes based on original notebook\n            num_layer=args.num_layer,\n            emb_dim=args.emb_dim,\n            drop_ratio=args.drop_ratio,\n            virtual_node=args.virtual_node,\n            residual=args.residual,\n            JK=args.JK,\n            graph_pooling=args.graph_pooling,\n            edge_drop_ratio = args.edge_drop_ratio,\n            batch_norm=args.batch_norm\n           )\n\nmodel = model.to(device)\n\n# Setup optimizer and loss\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n\nif args.baseline_mode == 2:\n    criterion = NoisyCrossEntropyLoss(args.noise_prob)\n    print(f\"Using Noisy Cross Entropy Loss (p={args.noise_prob})\")\nelif args.baseline_mode == 3: # <--- ADD THIS BLOCK FOR GCE\n    criterion = GeneralizedCrossEntropyLoss(q=args.gce_q)\n    print(f\"Using Generalized Cross Entropy (GCE) Loss (q={args.gce_q})\")\nelse:\n    criterion = torch.nn.CrossEntropyLoss()\n    print(\"Using standard Cross Entropy Loss\")\n\nprint(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n\n# Setup logging and checkpoints\n#exp_name = f\"{args.gnn}_dataset{args.dataset}_mode{args.train_mode}\"\nexp_name = f\"gin_dataset{args.dataset}_mode{args.train_mode}\"\nlogs_dir = os.path.join(\"logs\", exp_name)\ncheckpoints_dir = os.path.join(\"checkpoints\", exp_name)\nos.makedirs(logs_dir, exist_ok=True)\nos.makedirs(checkpoints_dir, exist_ok=True)\n\n# Setup logging\nlog_file = os.path.join(logs_dir, \"training.log\")\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(message)s',\n    handlers=[\n        logging.FileHandler(log_file),\n        logging.StreamHandler()\n    ]\n)\n\n#best_model_path = os.path.join(checkpoints_dir, \"best_model.pth\")\nbest_model_path = '/kaggle/working/best_model.pth'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T18:01:13.454082Z","iopub.execute_input":"2025-05-28T18:01:13.454328Z","iopub.status.idle":"2025-05-28T18:01:13.724965Z","shell.execute_reply.started":"2025-05-28T18:01:13.454305Z","shell.execute_reply":"2025-05-28T18:01:13.724408Z"}},"outputs":[{"name":"stdout","text":"\n========================================\nMODEL SETUP\n========================================\nUsing Generalized Cross Entropy (GCE) Loss (q=0.5)\nModel parameters: 1,330,953\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"## 8. Main training loop","metadata":{}},{"cell_type":"markdown","source":"### 7.4 Training loop\n","metadata":{}},{"cell_type":"code","source":"print(\"\\n\" + \"=\"*40)\nprint(\"TRAINING\")\nprint(\"=\"*40)\n\nbest_val_accuracy = 0.0\ntrain_losses = []\ntrain_accuracies = []\nval_losses = []\nval_accuracies = []\n\n# Early stopping variables\nif args.early_stopping:\n    epochs_without_improvement = 0\n    print(f\"Early stopping enabled with patience: {args.patience}\")\nelse:\n    print(\"Early stopping disabled\")\n\n# Calculate checkpoint intervals\nif args.num_checkpoints > 1:\n    checkpoint_intervals = [int((i + 1) * args.epochs / args.num_checkpoints) \n                          for i in range(args.num_checkpoints)]\nelse:\n    checkpoint_intervals = [args.epochs]\n\nfor epoch in range(args.epochs):\n    print(f\"\\nEpoch {epoch + 1}/{args.epochs}\")\n    print(\"-\" * 30)\n    \n    # Training\n    train_loss, train_acc = train(\n        train_loader, model, optimizer, criterion, device,\n        save_checkpoints=(epoch + 1 in checkpoint_intervals),\n        checkpoint_path=os.path.join(checkpoints_dir, \"checkpoint\"),\n        current_epoch=epoch\n    )\n    \n    # Validation\n    val_loss, val_acc = evaluate(val_loader, model, criterion, device, calculate_accuracy=True)\n    \n    # Log results\n    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n    \n    logging.info(f\"Epoch {epoch + 1}: Train Loss={train_loss:.4f}, Train Acc={train_acc:.4f}, \"\n                f\"Val Loss={val_loss:.4f}, Val Acc={val_acc:.4f}\")\n    \n    # Store metrics\n    train_losses.append(train_loss)\n    train_accuracies.append(train_acc)\n    val_losses.append(val_loss)\n    val_accuracies.append(val_acc)\n    \n    # Save best model\n    if val_acc > best_val_accuracy:\n        best_val_accuracy = val_acc\n        torch.save(model.state_dict(), best_model_path)\n        print(f\"★ New best model saved! Val Acc: {val_acc:.4f}\")\n\n        # Reset early stopping counter\n        if args.early_stopping:\n            epochs_without_improvement = 0\n\n    else:\n        # No improvement\n        if args.early_stopping:\n            epochs_without_improvement += 1\n            print(f\"No improvement for {epochs_without_improvement} epoch(s)\")\n            \n            # Check if we should stop early\n            if epochs_without_improvement >= args.patience:\n                print(f\"\\nEarly stopping triggered! No improvement for {args.patience} epochs.\")\n                print(f\"Best validation accuracy: {best_val_accuracy:.4f}\")\n                break\n\nprint(f\"\\nBest validation accuracy: {best_val_accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T18:01:13.725655Z","iopub.execute_input":"2025-05-28T18:01:13.725833Z","execution_failed":"2025-05-28T18:20:23.682Z"}},"outputs":[{"name":"stdout","text":"\n========================================\nTRAINING\n========================================\nEarly stopping enabled with patience: 25\n\nEpoch 1/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.30batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:00<00:00, 18.27batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.1188, Train Acc: 0.2837\nVal Loss: 1.0594, Val Acc: 0.3502\n★ New best model saved! Val Acc: 0.3502\n\nEpoch 2/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:16<00:00,  9.91batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:00<00:00, 18.15batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.0424, Train Acc: 0.3658\nVal Loss: 1.0274, Val Acc: 0.3590\n★ New best model saved! Val Acc: 0.3590\n\nEpoch 3/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:16<00:00,  9.80batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 17.85batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.0006, Train Acc: 0.3929\nVal Loss: 1.0014, Val Acc: 0.3750\n★ New best model saved! Val Acc: 0.3750\n\nEpoch 4/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:16<00:00,  9.66batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 17.83batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.9706, Train Acc: 0.4123\nVal Loss: 0.9456, Val Acc: 0.4105\n★ New best model saved! Val Acc: 0.4105\n\nEpoch 5/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:16<00:00,  9.51batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 17.52batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.9456, Train Acc: 0.4296\nVal Loss: 1.1056, Val Acc: 0.3342\nNo improvement for 1 epoch(s)\n\nEpoch 6/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:16<00:00,  9.37batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 17.08batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.9181, Train Acc: 0.4451\nVal Loss: 0.9807, Val Acc: 0.4043\nNo improvement for 2 epoch(s)\n\nEpoch 7/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.18batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 16.62batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.9000, Train Acc: 0.4602\nVal Loss: 0.9318, Val Acc: 0.4309\n★ New best model saved! Val Acc: 0.4309\n\nEpoch 8/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  8.97batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 16.86batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.8825, Train Acc: 0.4741\nVal Loss: 0.9096, Val Acc: 0.4424\n★ New best model saved! Val Acc: 0.4424\n\nEpoch 9/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.00batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 16.46batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.8783, Train Acc: 0.4785\nVal Loss: 1.0921, Val Acc: 0.3289\nNo improvement for 1 epoch(s)\n\nEpoch 10/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.09batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 16.72batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.8700, Train Acc: 0.4822\nVal Loss: 1.0117, Val Acc: 0.3883\nNo improvement for 2 epoch(s)\n\nEpoch 11/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.10batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 16.79batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.8602, Train Acc: 0.4885\nVal Loss: 0.9503, Val Acc: 0.4264\nNo improvement for 3 epoch(s)\n\nEpoch 12/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.10batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 16.62batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.8530, Train Acc: 0.4970\nVal Loss: 0.9931, Val Acc: 0.3998\nNo improvement for 4 epoch(s)\n\nEpoch 13/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.03batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 16.69batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.8419, Train Acc: 0.5029\nVal Loss: 1.1644, Val Acc: 0.3422\nNo improvement for 5 epoch(s)\n\nEpoch 14/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.13batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 17.05batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.8348, Train Acc: 0.5072\nVal Loss: 0.8639, Val Acc: 0.4707\n★ New best model saved! Val Acc: 0.4707\n\nEpoch 15/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.14batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 17.10batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.8347, Train Acc: 0.5048\nVal Loss: 0.8906, Val Acc: 0.4707\nNo improvement for 1 epoch(s)\n\nEpoch 16/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.18batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 17.04batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.8205, Train Acc: 0.5154\nVal Loss: 0.8320, Val Acc: 0.5044\n★ New best model saved! Val Acc: 0.5044\n\nEpoch 17/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.19batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 17.08batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.8233, Train Acc: 0.5157\nVal Loss: 0.9333, Val Acc: 0.4530\nNo improvement for 1 epoch(s)\n\nEpoch 18/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.12batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 16.91batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.8202, Train Acc: 0.5159\nVal Loss: 1.2788, Val Acc: 0.2828\nNo improvement for 2 epoch(s)\n\nEpoch 19/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.08batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 16.89batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.8077, Train Acc: 0.5273\nVal Loss: 1.0768, Val Acc: 0.3697\nNo improvement for 3 epoch(s)\n\nEpoch 20/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.07batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 16.71batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.8098, Train Acc: 0.5227\nVal Loss: 1.4328, Val Acc: 0.2234\nNo improvement for 4 epoch(s)\n\nEpoch 21/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.13batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 17.15batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.8016, Train Acc: 0.5312\nVal Loss: 0.8453, Val Acc: 0.4956\nNo improvement for 5 epoch(s)\n\nEpoch 22/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.16batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 17.04batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7953, Train Acc: 0.5344\nVal Loss: 1.0638, Val Acc: 0.3475\nNo improvement for 6 epoch(s)\n\nEpoch 23/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.16batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 16.91batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7943, Train Acc: 0.5329\nVal Loss: 1.1250, Val Acc: 0.3404\nNo improvement for 7 epoch(s)\n\nEpoch 24/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.16batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 16.73batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7897, Train Acc: 0.5369\nVal Loss: 0.8124, Val Acc: 0.5124\n★ New best model saved! Val Acc: 0.5124\n\nEpoch 25/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.14batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 17.00batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7790, Train Acc: 0.5430\nVal Loss: 0.9149, Val Acc: 0.4504\nNo improvement for 1 epoch(s)\n\nEpoch 26/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.14batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 16.98batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7777, Train Acc: 0.5473\nVal Loss: 0.9321, Val Acc: 0.4512\nNo improvement for 2 epoch(s)\n\nEpoch 27/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.15batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 16.99batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7763, Train Acc: 0.5500\nVal Loss: 0.8949, Val Acc: 0.4557\nNo improvement for 3 epoch(s)\n\nEpoch 28/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.13batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 16.96batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7690, Train Acc: 0.5513\nVal Loss: 1.0796, Val Acc: 0.3768\nNo improvement for 4 epoch(s)\n\nEpoch 29/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.15batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 17.08batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7646, Train Acc: 0.5552\nVal Loss: 1.0012, Val Acc: 0.4193\nNo improvement for 5 epoch(s)\n\nEpoch 30/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.15batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 17.09batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7603, Train Acc: 0.5611\nVal Loss: 0.8989, Val Acc: 0.4654\nNo improvement for 6 epoch(s)\n\nEpoch 31/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.13batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 17.07batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7560, Train Acc: 0.5625\nVal Loss: 0.9032, Val Acc: 0.4504\nNo improvement for 7 epoch(s)\n\nEpoch 32/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.15batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 17.04batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7496, Train Acc: 0.5652\nVal Loss: 0.9267, Val Acc: 0.4441\nNo improvement for 8 epoch(s)\n\nEpoch 33/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.10batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 16.86batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7501, Train Acc: 0.5643\nVal Loss: 0.7824, Val Acc: 0.5346\n★ New best model saved! Val Acc: 0.5346\n\nEpoch 34/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.08batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 16.49batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7441, Train Acc: 0.5705\nVal Loss: 0.8730, Val Acc: 0.4902\nNo improvement for 1 epoch(s)\n\nEpoch 35/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.03batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 16.69batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7471, Train Acc: 0.5642\nVal Loss: 0.7742, Val Acc: 0.5355\n★ New best model saved! Val Acc: 0.5355\n\nEpoch 36/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.04batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 16.80batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7401, Train Acc: 0.5722\nVal Loss: 0.9576, Val Acc: 0.4450\nNo improvement for 1 epoch(s)\n\nEpoch 37/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.05batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 16.67batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7333, Train Acc: 0.5761\nVal Loss: 0.8853, Val Acc: 0.4840\nNo improvement for 2 epoch(s)\n\nEpoch 38/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.07batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 17.01batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7389, Train Acc: 0.5720\nVal Loss: 0.8550, Val Acc: 0.4902\nNo improvement for 3 epoch(s)\n\nEpoch 39/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.16batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 17.04batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7264, Train Acc: 0.5800\nVal Loss: 1.0766, Val Acc: 0.3502\nNo improvement for 4 epoch(s)\n\nEpoch 40/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.14batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 17.03batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7238, Train Acc: 0.5808\nVal Loss: 0.8576, Val Acc: 0.4920\nNo improvement for 5 epoch(s)\n\nEpoch 41/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.14batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 16.76batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7247, Train Acc: 0.5840\nVal Loss: 0.9737, Val Acc: 0.4087\nNo improvement for 6 epoch(s)\n\nEpoch 42/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.09batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 16.86batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7230, Train Acc: 0.5834\nVal Loss: 0.8674, Val Acc: 0.5027\nNo improvement for 7 epoch(s)\n\nEpoch 43/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.06batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 16.76batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7251, Train Acc: 0.5823\nVal Loss: 0.7964, Val Acc: 0.5266\nNo improvement for 8 epoch(s)\n\nEpoch 44/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.08batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 16.64batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7201, Train Acc: 0.5868\nVal Loss: 0.7799, Val Acc: 0.5426\n★ New best model saved! Val Acc: 0.5426\n\nEpoch 45/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.04batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 16.77batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7240, Train Acc: 0.5830\nVal Loss: 1.0891, Val Acc: 0.3741\nNo improvement for 1 epoch(s)\n\nEpoch 46/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.06batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 16.74batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7230, Train Acc: 0.5831\nVal Loss: 0.8392, Val Acc: 0.5080\nNo improvement for 2 epoch(s)\n\nEpoch 47/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.05batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 16.72batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7152, Train Acc: 0.5884\nVal Loss: 0.7843, Val Acc: 0.5363\nNo improvement for 3 epoch(s)\n\nEpoch 48/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.04batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 16.79batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7070, Train Acc: 0.5923\nVal Loss: 1.2438, Val Acc: 0.3218\nNo improvement for 4 epoch(s)\n\nEpoch 49/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.06batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 16.71batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7175, Train Acc: 0.5865\nVal Loss: 0.9361, Val Acc: 0.4397\nNo improvement for 5 epoch(s)\n\nEpoch 50/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.05batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 16.77batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7106, Train Acc: 0.5929\nVal Loss: 0.8493, Val Acc: 0.4894\nNo improvement for 6 epoch(s)\n\nEpoch 51/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.06batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 16.68batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7050, Train Acc: 0.5948\nVal Loss: 0.8179, Val Acc: 0.5089\nNo improvement for 7 epoch(s)\n\nEpoch 52/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.06batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 16.75batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7009, Train Acc: 0.6018\nVal Loss: 1.0075, Val Acc: 0.4025\nNo improvement for 8 epoch(s)\n\nEpoch 53/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.07batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 16.82batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.6976, Train Acc: 0.6008\nVal Loss: 0.9469, Val Acc: 0.4530\nNo improvement for 9 epoch(s)\n\nEpoch 54/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.07batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 16.74batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.6958, Train Acc: 0.6019\nVal Loss: 1.0443, Val Acc: 0.3972\nNo improvement for 10 epoch(s)\n\nEpoch 55/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.06batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 16.76batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7011, Train Acc: 0.5961\nVal Loss: 0.8238, Val Acc: 0.5195\nNo improvement for 11 epoch(s)\n\nEpoch 56/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.06batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 16.73batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.6982, Train Acc: 0.6022\nVal Loss: 0.9048, Val Acc: 0.4601\nNo improvement for 12 epoch(s)\n\nEpoch 57/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.05batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 16.76batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.6954, Train Acc: 0.6021\nVal Loss: 0.8597, Val Acc: 0.5000\nNo improvement for 13 epoch(s)\n\nEpoch 58/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.05batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 16.68batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.6909, Train Acc: 0.6062\nVal Loss: 0.9003, Val Acc: 0.4566\nNo improvement for 14 epoch(s)\n\nEpoch 59/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.06batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 16.79batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.6888, Train Acc: 0.6072\nVal Loss: 0.8095, Val Acc: 0.5195\nNo improvement for 15 epoch(s)\n\nEpoch 60/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.05batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 16.76batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.6838, Train Acc: 0.6109\nVal Loss: 0.7360, Val Acc: 0.5665\n★ New best model saved! Val Acc: 0.5665\n\nEpoch 61/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.06batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 16.70batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.6820, Train Acc: 0.6095\nVal Loss: 1.0199, Val Acc: 0.4069\nNo improvement for 1 epoch(s)\n\nEpoch 62/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs: 100%|██████████| 159/159 [00:17<00:00,  9.06batch/s]\nIterating eval graphs: 100%|██████████| 18/18 [00:01<00:00, 16.82batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.6840, Train Acc: 0.6099\nVal Loss: 0.7430, Val Acc: 0.5674\n★ New best model saved! Val Acc: 0.5674\n\nEpoch 63/200\n------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Iterating training graphs:   4%|▍         | 6/159 [00:00<00:16,  9.53batch/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# Plot training progress\nplot_training_progress(train_losses, train_accuracies, val_losses, val_accuracies, logs_dir)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-28T18:20:23.683Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 7.5 Testing and predictions","metadata":{}},{"cell_type":"code","source":"print(\"\\n\" + \"=\"*40)\nprint(\"TESTING\")\nprint(\"=\"*40)\n\n# Load best model and make predictions\nmodel.load_state_dict(torch.load(best_model_path))\nprint(f\"Loaded best model from: {best_model_path}\")\n\npredictions = evaluate(test_loader, model, criterion, device, calculate_accuracy=False)\n\n# Save predictions\nsave_predictions(predictions, args.dataset)\n\n# Cleanup for memory\ndel train_dataset, val_dataset, test_dataset\ndel train_loader, val_loader, test_loader\ngc.collect()\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"TRAINING COMPLETED SUCCESSFULLY!\")\nprint(\"=\"*60)\nprint(f\"Best validation accuracy: {best_val_accuracy:.4f}\")\nprint(f\"Predictions saved for dataset {args.dataset}\")\nprint(f\"Logs and plots saved in: {logs_dir}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-28T18:20:23.683Z"}},"outputs":[],"execution_count":null}]}